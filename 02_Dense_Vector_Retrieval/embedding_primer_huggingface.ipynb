{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Embeddings and Dense Vector Search: A Quick Primer (HuggingFace Version)\n",
    "\n",
    "> **Note:** This notebook uses HuggingFace's `all-MiniLM-L6-v2` model instead of OpenAI. It runs completely locally with no API keys required!\n",
    "\n",
    "If you come from an NLP background, embeddings are something you might be intimately familiar with - otherwise, you might find the topic a bit...dense. (this attempt at a joke will make more sense later)\n",
    "\n",
    "In all seriousness, embeddings are a powerful piece of the NLP puzzle, so let's dive in!\n",
    "\n",
    "> NOTE: While this notebook is language/NLP-centric, embeddings have uses beyond just text!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Why Do We Even Need Embeddings?\n",
    "\n",
    "In order to fully understand what Embeddings are, we first need to understand why we have them!\n",
    "\n",
    "Machine Learning algorithms, ranging from the very big to the very small, all have one thing in common:\n",
    "\n",
    "They need numeric inputs.\n",
    "\n",
    "So we need a process by which to translate the domain we live in, dominated by images, audio, language, and more, into the domain of the machine: Numbers.\n",
    "\n",
    "Another thing we want to be able to do is capture \"semantic information\" about words/phrases so that we can use algorithmic approaches to determine if words are closely related or not!\n",
    "\n",
    "So, we need to come up with a process that does these two things well:\n",
    "\n",
    "- Convert non-numeric data into numeric-data\n",
    "- Capture potential semantic relationships between individual pieces of data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### How Do Embeddings Capture Semantic Relationships?\n",
    "\n",
    "In a simplified sense, embeddings map a word or phrase into n-dimensional space with a dense continuous vector, where each dimension in the vector represents some \"latent feature\" of the data.\n",
    "\n",
    "This is best represented in a classic example:\n",
    "\n",
    "![image](https://i.imgur.com/K5eQtmH.png)\n",
    "\n",
    "As can be seen in the extremely simplified example: The X_1 axis represents age, and the X_2 axis represents hair.\n",
    "\n",
    "The relationship of \"puppy -> dog\" reflects the same relationship as \"baby -> adult\", but dogs are (typically) hairier than humans. However, adults typically have more hair than babies - so they are shifted slightly closer to dogs on the X_2 axis!\n",
    "\n",
    "Now, this is a simplified and contrived example - but it is *essentially* the mechanism by which embeddings capture semantic information.\n",
    "\n",
    "In reality, the dimensions don't sincerely represent hard-concepts like \"age\" or \"hair\", but it's useful as a way to think about how the semantic relationships are captured.\n",
    "\n",
    "Alright, with some history behind us - let's examine how these might help us choose relevant context."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's begin with a simple example - simply looking at how close to embedding vectors are for a given phrase.\n",
    "\n",
    "When we use the term \"close\" in this notebook - we're referring to a distance measure called \"cosine similarity\".\n",
    "\n",
    "We discussed above that if two embeddings are close - they are semantically similar, cosine similarity gives us a quick way to measure how similar two vectors are!\n",
    "\n",
    "Closeness is measured from 1 to -1, with 1 being extremely close and -1 being extremely close to opposite in meaning.\n",
    "\n",
    "Let's implement it with Numpy below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from numpy.linalg import norm\n",
    "\n",
    "def cosine_similarity(vec_1, vec_2):\n",
    "    return np.dot(vec_1, vec_2) / (norm(vec_1) * norm(vec_2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Installing Dependencies\n",
    "\n",
    "First, we need to install the HuggingFace sentence-transformers library. This will download and manage the embedding models for us.\n",
    "\n",
    "> **Note:** This will also install PyTorch if you don't have it already. The first time you run the embedding model, it will download ~90MB."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install sentence-transformers -q"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now let's import and initialize our HuggingFace embedding model. We'll use the `all-MiniLM-L6-v2` model which is optimized for semantic search.\n",
    "\n",
    "> **Quick Info About `all-MiniLM-L6-v2`**:\n",
    "> - It has a max sequence length of **256** word pieces\n",
    "> - It returns vectors with dimension **384** (compared to OpenAI's 1536)\n",
    "> - It runs completely locally - no API key required!\n",
    "> - It's free and open source"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "import os\nimport certifi\n\n# Create a combined cert bundle with Zscaler for corporate network\nzscaler_cert = \"/path/to/your/zscaler.crt\"  # Update this path to your .crt file\ncombined_cert = \"/tmp/combined_certs.pem\"\n\nwith open(combined_cert, \"w\") as outfile:\n    with open(certifi.where(), \"r\") as certifi_file:\n        outfile.write(certifi_file.read())\n    with open(zscaler_cert, \"r\") as zscaler_file:\n        outfile.write(zscaler_file.read())\n\nos.environ['REQUESTS_CA_BUNDLE'] = combined_cert\nos.environ['SSL_CERT_FILE'] = combined_cert\nos.environ['CURL_CA_BUNDLE'] = combined_cert"
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "'[SSL: CERTIFICATE_VERIFY_FAILED] certificate verify failed: unable to get local issuer certificate (_ssl.c:1032)' thrown while requesting HEAD https://huggingface.co/sentence-transformers/all-MiniLM-L6-v2/resolve/main/./modules.json\n",
      "Retrying in 1s [Retry 1/5].\n",
      "No sentence-transformers model found with name sentence-transformers/all-MiniLM-L6-v2. Creating a new one with mean pooling.\n",
      "'[SSL: CERTIFICATE_VERIFY_FAILED] certificate verify failed: unable to get local issuer certificate (_ssl.c:1032)' thrown while requesting HEAD https://huggingface.co/sentence-transformers/all-MiniLM-L6-v2/resolve/main/adapter_config.json\n",
      "Retrying in 1s [Retry 1/5].\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "Cannot send a request, as the client has been closed.",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mRuntimeError\u001b[39m                              Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[1]\u001b[39m\u001b[32m, line 4\u001b[39m\n\u001b[32m      1\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01msentence_transformers\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m SentenceTransformer\n\u001b[32m      3\u001b[39m \u001b[38;5;66;03m# Initialize the model - this will download it on first run\u001b[39;00m\n\u001b[32m----> \u001b[39m\u001b[32m4\u001b[39m embedding_model = \u001b[43mSentenceTransformer\u001b[49m\u001b[43m(\u001b[49m\u001b[33;43m'\u001b[39;49m\u001b[33;43msentence-transformers/all-MiniLM-L6-v2\u001b[39;49m\u001b[33;43m'\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[32m      6\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mModel loaded: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00membedding_model\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m\"\u001b[39m)\n\u001b[32m      7\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mMax sequence length: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00membedding_model.max_seq_length\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m\"\u001b[39m)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/code/aimakerspace/02_Dense_Vector_Retrieval/.venv/lib/python3.13/site-packages/sentence_transformers/SentenceTransformer.py:339\u001b[39m, in \u001b[36mSentenceTransformer.__init__\u001b[39m\u001b[34m(self, model_name_or_path, modules, device, prompts, default_prompt_name, similarity_fn_name, cache_folder, trust_remote_code, revision, local_files_only, token, use_auth_token, truncate_dim, model_kwargs, tokenizer_kwargs, config_kwargs, model_card_data, backend)\u001b[39m\n\u001b[32m    327\u001b[39m         modules, \u001b[38;5;28mself\u001b[39m.module_kwargs = \u001b[38;5;28mself\u001b[39m._load_sbert_model(\n\u001b[32m    328\u001b[39m             model_name_or_path,\n\u001b[32m    329\u001b[39m             token=token,\n\u001b[32m   (...)\u001b[39m\u001b[32m    336\u001b[39m             config_kwargs=config_kwargs,\n\u001b[32m    337\u001b[39m         )\n\u001b[32m    338\u001b[39m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m339\u001b[39m         modules = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_load_auto_model\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    340\u001b[39m \u001b[43m            \u001b[49m\u001b[43mmodel_name_or_path\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    341\u001b[39m \u001b[43m            \u001b[49m\u001b[43mtoken\u001b[49m\u001b[43m=\u001b[49m\u001b[43mtoken\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    342\u001b[39m \u001b[43m            \u001b[49m\u001b[43mcache_folder\u001b[49m\u001b[43m=\u001b[49m\u001b[43mcache_folder\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    343\u001b[39m \u001b[43m            \u001b[49m\u001b[43mrevision\u001b[49m\u001b[43m=\u001b[49m\u001b[43mrevision\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    344\u001b[39m \u001b[43m            \u001b[49m\u001b[43mtrust_remote_code\u001b[49m\u001b[43m=\u001b[49m\u001b[43mtrust_remote_code\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    345\u001b[39m \u001b[43m            \u001b[49m\u001b[43mlocal_files_only\u001b[49m\u001b[43m=\u001b[49m\u001b[43mlocal_files_only\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    346\u001b[39m \u001b[43m            \u001b[49m\u001b[43mmodel_kwargs\u001b[49m\u001b[43m=\u001b[49m\u001b[43mmodel_kwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    347\u001b[39m \u001b[43m            \u001b[49m\u001b[43mtokenizer_kwargs\u001b[49m\u001b[43m=\u001b[49m\u001b[43mtokenizer_kwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    348\u001b[39m \u001b[43m            \u001b[49m\u001b[43mconfig_kwargs\u001b[49m\u001b[43m=\u001b[49m\u001b[43mconfig_kwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    349\u001b[39m \u001b[43m            \u001b[49m\u001b[43mhas_modules\u001b[49m\u001b[43m=\u001b[49m\u001b[43mhas_modules\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    350\u001b[39m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    352\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m modules \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(modules, OrderedDict):\n\u001b[32m    353\u001b[39m     modules = OrderedDict([(\u001b[38;5;28mstr\u001b[39m(idx), module) \u001b[38;5;28;01mfor\u001b[39;00m idx, module \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28menumerate\u001b[39m(modules)])\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/code/aimakerspace/02_Dense_Vector_Retrieval/.venv/lib/python3.13/site-packages/sentence_transformers/SentenceTransformer.py:2112\u001b[39m, in \u001b[36mSentenceTransformer._load_auto_model\u001b[39m\u001b[34m(self, model_name_or_path, token, cache_folder, revision, trust_remote_code, local_files_only, model_kwargs, tokenizer_kwargs, config_kwargs, has_modules)\u001b[39m\n\u001b[32m   2109\u001b[39m tokenizer_kwargs = shared_kwargs \u001b[38;5;28;01mif\u001b[39;00m tokenizer_kwargs \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;28;01melse\u001b[39;00m {**shared_kwargs, **tokenizer_kwargs}\n\u001b[32m   2110\u001b[39m config_kwargs = shared_kwargs \u001b[38;5;28;01mif\u001b[39;00m config_kwargs \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;28;01melse\u001b[39;00m {**shared_kwargs, **config_kwargs}\n\u001b[32m-> \u001b[39m\u001b[32m2112\u001b[39m transformer_model = \u001b[43mTransformer\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m   2113\u001b[39m \u001b[43m    \u001b[49m\u001b[43mmodel_name_or_path\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   2114\u001b[39m \u001b[43m    \u001b[49m\u001b[43mcache_dir\u001b[49m\u001b[43m=\u001b[49m\u001b[43mcache_folder\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   2115\u001b[39m \u001b[43m    \u001b[49m\u001b[43mmodel_args\u001b[49m\u001b[43m=\u001b[49m\u001b[43mmodel_kwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   2116\u001b[39m \u001b[43m    \u001b[49m\u001b[43mtokenizer_args\u001b[49m\u001b[43m=\u001b[49m\u001b[43mtokenizer_kwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   2117\u001b[39m \u001b[43m    \u001b[49m\u001b[43mconfig_args\u001b[49m\u001b[43m=\u001b[49m\u001b[43mconfig_kwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   2118\u001b[39m \u001b[43m    \u001b[49m\u001b[43mbackend\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mbackend\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   2119\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   2120\u001b[39m pooling_model = Pooling(transformer_model.get_word_embedding_dimension(), \u001b[33m\"\u001b[39m\u001b[33mmean\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m   2121\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m local_files_only:\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/code/aimakerspace/02_Dense_Vector_Retrieval/.venv/lib/python3.13/site-packages/sentence_transformers/models/Transformer.py:88\u001b[39m, in \u001b[36mTransformer.__init__\u001b[39m\u001b[34m(self, model_name_or_path, max_seq_length, model_args, tokenizer_args, config_args, cache_dir, do_lower_case, tokenizer_name_or_path, backend)\u001b[39m\n\u001b[32m     85\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m config_args \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[32m     86\u001b[39m     config_args = {}\n\u001b[32m---> \u001b[39m\u001b[32m88\u001b[39m config, is_peft_model = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_load_config\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel_name_or_path\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcache_dir\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbackend\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mconfig_args\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     89\u001b[39m \u001b[38;5;28mself\u001b[39m._load_model(model_name_or_path, config, cache_dir, backend, is_peft_model, **model_args)\n\u001b[32m     91\u001b[39m \u001b[38;5;66;03m# Get the signature of the auto_model's forward method to pass only the expected arguments from `features`,\u001b[39;00m\n\u001b[32m     92\u001b[39m \u001b[38;5;66;03m# plus some common values like \"input_ids\", \"attention_mask\", etc.\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/code/aimakerspace/02_Dense_Vector_Retrieval/.venv/lib/python3.13/site-packages/sentence_transformers/models/Transformer.py:139\u001b[39m, in \u001b[36mTransformer._load_config\u001b[39m\u001b[34m(self, model_name_or_path, cache_dir, backend, config_args)\u001b[39m\n\u001b[32m    123\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34m_load_config\u001b[39m(\n\u001b[32m    124\u001b[39m     \u001b[38;5;28mself\u001b[39m, model_name_or_path: \u001b[38;5;28mstr\u001b[39m, cache_dir: \u001b[38;5;28mstr\u001b[39m | \u001b[38;5;28;01mNone\u001b[39;00m, backend: \u001b[38;5;28mstr\u001b[39m, config_args: \u001b[38;5;28mdict\u001b[39m[\u001b[38;5;28mstr\u001b[39m, Any]\n\u001b[32m    125\u001b[39m ) -> \u001b[38;5;28mtuple\u001b[39m[PeftConfig | PretrainedConfig, \u001b[38;5;28mbool\u001b[39m]:\n\u001b[32m    126\u001b[39m \u001b[38;5;250m    \u001b[39m\u001b[33;03m\"\"\"Loads the transformers or PEFT configuration\u001b[39;00m\n\u001b[32m    127\u001b[39m \n\u001b[32m    128\u001b[39m \u001b[33;03m    Args:\u001b[39;00m\n\u001b[32m   (...)\u001b[39m\u001b[32m    136\u001b[39m \u001b[33;03m        tuple[PretrainedConfig, bool]: The model configuration and a boolean indicating whether the model is a PEFT model.\u001b[39;00m\n\u001b[32m    137\u001b[39m \u001b[33;03m    \"\"\"\u001b[39;00m\n\u001b[32m    138\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m (\n\u001b[32m--> \u001b[39m\u001b[32m139\u001b[39m         \u001b[43mfind_adapter_config_file\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    140\u001b[39m \u001b[43m            \u001b[49m\u001b[43mmodel_name_or_path\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    141\u001b[39m \u001b[43m            \u001b[49m\u001b[43mcache_dir\u001b[49m\u001b[43m=\u001b[49m\u001b[43mcache_dir\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    142\u001b[39m \u001b[43m            \u001b[49m\u001b[43mtoken\u001b[49m\u001b[43m=\u001b[49m\u001b[43mconfig_args\u001b[49m\u001b[43m.\u001b[49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mtoken\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    143\u001b[39m \u001b[43m            \u001b[49m\u001b[43mrevision\u001b[49m\u001b[43m=\u001b[49m\u001b[43mconfig_args\u001b[49m\u001b[43m.\u001b[49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mrevision\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    144\u001b[39m \u001b[43m            \u001b[49m\u001b[43mlocal_files_only\u001b[49m\u001b[43m=\u001b[49m\u001b[43mconfig_args\u001b[49m\u001b[43m.\u001b[49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mlocal_files_only\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    145\u001b[39m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    146\u001b[39m         \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m    147\u001b[39m     ):\n\u001b[32m    148\u001b[39m         \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m is_peft_available():\n\u001b[32m    149\u001b[39m             \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m(\n\u001b[32m    150\u001b[39m                 \u001b[33m\"\u001b[39m\u001b[33mLoading a PEFT model requires installing the `peft` package. You can install it via `pip install peft`.\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m    151\u001b[39m             )\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/code/aimakerspace/02_Dense_Vector_Retrieval/.venv/lib/python3.13/site-packages/transformers/utils/peft_utils.py:83\u001b[39m, in \u001b[36mfind_adapter_config_file\u001b[39m\u001b[34m(model_id, cache_dir, force_download, proxies, token, revision, local_files_only, subfolder, _commit_hash)\u001b[39m\n\u001b[32m     81\u001b[39m         adapter_cached_filename = os.path.join(model_id, ADAPTER_CONFIG_NAME)\n\u001b[32m     82\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m---> \u001b[39m\u001b[32m83\u001b[39m     adapter_cached_filename = \u001b[43mcached_file\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m     84\u001b[39m \u001b[43m        \u001b[49m\u001b[43mmodel_id\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     85\u001b[39m \u001b[43m        \u001b[49m\u001b[43mADAPTER_CONFIG_NAME\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     86\u001b[39m \u001b[43m        \u001b[49m\u001b[43mcache_dir\u001b[49m\u001b[43m=\u001b[49m\u001b[43mcache_dir\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     87\u001b[39m \u001b[43m        \u001b[49m\u001b[43mforce_download\u001b[49m\u001b[43m=\u001b[49m\u001b[43mforce_download\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     88\u001b[39m \u001b[43m        \u001b[49m\u001b[43mproxies\u001b[49m\u001b[43m=\u001b[49m\u001b[43mproxies\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     89\u001b[39m \u001b[43m        \u001b[49m\u001b[43mtoken\u001b[49m\u001b[43m=\u001b[49m\u001b[43mtoken\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     90\u001b[39m \u001b[43m        \u001b[49m\u001b[43mrevision\u001b[49m\u001b[43m=\u001b[49m\u001b[43mrevision\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     91\u001b[39m \u001b[43m        \u001b[49m\u001b[43mlocal_files_only\u001b[49m\u001b[43m=\u001b[49m\u001b[43mlocal_files_only\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     92\u001b[39m \u001b[43m        \u001b[49m\u001b[43msubfolder\u001b[49m\u001b[43m=\u001b[49m\u001b[43msubfolder\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     93\u001b[39m \u001b[43m        \u001b[49m\u001b[43m_commit_hash\u001b[49m\u001b[43m=\u001b[49m\u001b[43m_commit_hash\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     94\u001b[39m \u001b[43m        \u001b[49m\u001b[43m_raise_exceptions_for_gated_repo\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[32m     95\u001b[39m \u001b[43m        \u001b[49m\u001b[43m_raise_exceptions_for_missing_entries\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[32m     96\u001b[39m \u001b[43m        \u001b[49m\u001b[43m_raise_exceptions_for_connection_errors\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[32m     97\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     99\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m adapter_cached_filename\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/code/aimakerspace/02_Dense_Vector_Retrieval/.venv/lib/python3.13/site-packages/transformers/utils/hub.py:276\u001b[39m, in \u001b[36mcached_file\u001b[39m\u001b[34m(path_or_repo_id, filename, **kwargs)\u001b[39m\n\u001b[32m    221\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mcached_file\u001b[39m(\n\u001b[32m    222\u001b[39m     path_or_repo_id: \u001b[38;5;28mstr\u001b[39m | os.PathLike,\n\u001b[32m    223\u001b[39m     filename: \u001b[38;5;28mstr\u001b[39m,\n\u001b[32m    224\u001b[39m     **kwargs,\n\u001b[32m    225\u001b[39m ) -> \u001b[38;5;28mstr\u001b[39m | \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[32m    226\u001b[39m \u001b[38;5;250m    \u001b[39m\u001b[33;03m\"\"\"\u001b[39;00m\n\u001b[32m    227\u001b[39m \u001b[33;03m    Tries to locate a file in a local folder and repo, downloads and cache it if necessary.\u001b[39;00m\n\u001b[32m    228\u001b[39m \n\u001b[32m   (...)\u001b[39m\u001b[32m    274\u001b[39m \u001b[33;03m    ```\u001b[39;00m\n\u001b[32m    275\u001b[39m \u001b[33;03m    \"\"\"\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m276\u001b[39m     file = \u001b[43mcached_files\u001b[49m\u001b[43m(\u001b[49m\u001b[43mpath_or_repo_id\u001b[49m\u001b[43m=\u001b[49m\u001b[43mpath_or_repo_id\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfilenames\u001b[49m\u001b[43m=\u001b[49m\u001b[43m[\u001b[49m\u001b[43mfilename\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    277\u001b[39m     file = file[\u001b[32m0\u001b[39m] \u001b[38;5;28;01mif\u001b[39;00m file \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;28;01melse\u001b[39;00m file\n\u001b[32m    278\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m file\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/code/aimakerspace/02_Dense_Vector_Retrieval/.venv/lib/python3.13/site-packages/transformers/utils/hub.py:507\u001b[39m, in \u001b[36mcached_files\u001b[39m\u001b[34m(path_or_repo_id, filenames, cache_dir, force_download, proxies, token, revision, local_files_only, subfolder, repo_type, user_agent, _raise_exceptions_for_gated_repo, _raise_exceptions_for_missing_entries, _raise_exceptions_for_connection_errors, _commit_hash, **deprecated_kwargs)\u001b[39m\n\u001b[32m    504\u001b[39m     \u001b[38;5;66;03m# Any other Exception type should now be re-raised, in order to provide helpful error messages and break the execution flow\u001b[39;00m\n\u001b[32m    505\u001b[39m     \u001b[38;5;66;03m# (EntryNotFoundError will be treated outside this block and correctly re-raised if needed)\u001b[39;00m\n\u001b[32m    506\u001b[39m     \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(e, EntryNotFoundError):\n\u001b[32m--> \u001b[39m\u001b[32m507\u001b[39m         \u001b[38;5;28;01mraise\u001b[39;00m e\n\u001b[32m    509\u001b[39m resolved_files = [\n\u001b[32m    510\u001b[39m     _get_cache_file_to_return(path_or_repo_id, filename, cache_dir, revision) \u001b[38;5;28;01mfor\u001b[39;00m filename \u001b[38;5;129;01min\u001b[39;00m full_filenames\n\u001b[32m    511\u001b[39m ]\n\u001b[32m    512\u001b[39m \u001b[38;5;66;03m# If there are any missing file and the flag is active, raise\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/code/aimakerspace/02_Dense_Vector_Retrieval/.venv/lib/python3.13/site-packages/transformers/utils/hub.py:419\u001b[39m, in \u001b[36mcached_files\u001b[39m\u001b[34m(path_or_repo_id, filenames, cache_dir, force_download, proxies, token, revision, local_files_only, subfolder, repo_type, user_agent, _raise_exceptions_for_gated_repo, _raise_exceptions_for_missing_entries, _raise_exceptions_for_connection_errors, _commit_hash, **deprecated_kwargs)\u001b[39m\n\u001b[32m    416\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m    417\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(full_filenames) == \u001b[32m1\u001b[39m:\n\u001b[32m    418\u001b[39m         \u001b[38;5;66;03m# This is slightly better for only 1 file\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m419\u001b[39m         \u001b[43mhf_hub_download\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    420\u001b[39m \u001b[43m            \u001b[49m\u001b[43mpath_or_repo_id\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    421\u001b[39m \u001b[43m            \u001b[49m\u001b[43mfilenames\u001b[49m\u001b[43m[\u001b[49m\u001b[32;43m0\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    422\u001b[39m \u001b[43m            \u001b[49m\u001b[43msubfolder\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mif\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43mlen\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43msubfolder\u001b[49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[43m==\u001b[49m\u001b[43m \u001b[49m\u001b[32;43m0\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01melse\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43msubfolder\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    423\u001b[39m \u001b[43m            \u001b[49m\u001b[43mrepo_type\u001b[49m\u001b[43m=\u001b[49m\u001b[43mrepo_type\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    424\u001b[39m \u001b[43m            \u001b[49m\u001b[43mrevision\u001b[49m\u001b[43m=\u001b[49m\u001b[43mrevision\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    425\u001b[39m \u001b[43m            \u001b[49m\u001b[43mcache_dir\u001b[49m\u001b[43m=\u001b[49m\u001b[43mcache_dir\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    426\u001b[39m \u001b[43m            \u001b[49m\u001b[43muser_agent\u001b[49m\u001b[43m=\u001b[49m\u001b[43muser_agent\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    427\u001b[39m \u001b[43m            \u001b[49m\u001b[43mforce_download\u001b[49m\u001b[43m=\u001b[49m\u001b[43mforce_download\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    428\u001b[39m \u001b[43m            \u001b[49m\u001b[43mproxies\u001b[49m\u001b[43m=\u001b[49m\u001b[43mproxies\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    429\u001b[39m \u001b[43m            \u001b[49m\u001b[43mtoken\u001b[49m\u001b[43m=\u001b[49m\u001b[43mtoken\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    430\u001b[39m \u001b[43m            \u001b[49m\u001b[43mlocal_files_only\u001b[49m\u001b[43m=\u001b[49m\u001b[43mlocal_files_only\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    431\u001b[39m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    432\u001b[39m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m    433\u001b[39m         snapshot_download(\n\u001b[32m    434\u001b[39m             path_or_repo_id,\n\u001b[32m    435\u001b[39m             allow_patterns=full_filenames,\n\u001b[32m   (...)\u001b[39m\u001b[32m    443\u001b[39m             local_files_only=local_files_only,\n\u001b[32m    444\u001b[39m         )\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/code/aimakerspace/02_Dense_Vector_Retrieval/.venv/lib/python3.13/site-packages/huggingface_hub/utils/_validators.py:89\u001b[39m, in \u001b[36mvalidate_hf_hub_args.<locals>._inner_fn\u001b[39m\u001b[34m(*args, **kwargs)\u001b[39m\n\u001b[32m     85\u001b[39m         validate_repo_id(arg_value)\n\u001b[32m     87\u001b[39m kwargs = smoothly_deprecate_legacy_arguments(fn_name=fn.\u001b[34m__name__\u001b[39m, kwargs=kwargs)\n\u001b[32m---> \u001b[39m\u001b[32m89\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfn\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/code/aimakerspace/02_Dense_Vector_Retrieval/.venv/lib/python3.13/site-packages/huggingface_hub/file_download.py:1024\u001b[39m, in \u001b[36mhf_hub_download\u001b[39m\u001b[34m(repo_id, filename, subfolder, repo_type, revision, library_name, library_version, cache_dir, local_dir, user_agent, force_download, etag_timeout, token, local_files_only, headers, endpoint, tqdm_class, dry_run)\u001b[39m\n\u001b[32m   1003\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m _hf_hub_download_to_local_dir(\n\u001b[32m   1004\u001b[39m         \u001b[38;5;66;03m# Destination\u001b[39;00m\n\u001b[32m   1005\u001b[39m         local_dir=local_dir,\n\u001b[32m   (...)\u001b[39m\u001b[32m   1021\u001b[39m         dry_run=dry_run,\n\u001b[32m   1022\u001b[39m     )\n\u001b[32m   1023\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m1024\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_hf_hub_download_to_cache_dir\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m   1025\u001b[39m \u001b[43m        \u001b[49m\u001b[38;5;66;43;03m# Destination\u001b[39;49;00m\n\u001b[32m   1026\u001b[39m \u001b[43m        \u001b[49m\u001b[43mcache_dir\u001b[49m\u001b[43m=\u001b[49m\u001b[43mcache_dir\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1027\u001b[39m \u001b[43m        \u001b[49m\u001b[38;5;66;43;03m# File info\u001b[39;49;00m\n\u001b[32m   1028\u001b[39m \u001b[43m        \u001b[49m\u001b[43mrepo_id\u001b[49m\u001b[43m=\u001b[49m\u001b[43mrepo_id\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1029\u001b[39m \u001b[43m        \u001b[49m\u001b[43mfilename\u001b[49m\u001b[43m=\u001b[49m\u001b[43mfilename\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1030\u001b[39m \u001b[43m        \u001b[49m\u001b[43mrepo_type\u001b[49m\u001b[43m=\u001b[49m\u001b[43mrepo_type\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1031\u001b[39m \u001b[43m        \u001b[49m\u001b[43mrevision\u001b[49m\u001b[43m=\u001b[49m\u001b[43mrevision\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1032\u001b[39m \u001b[43m        \u001b[49m\u001b[38;5;66;43;03m# HTTP info\u001b[39;49;00m\n\u001b[32m   1033\u001b[39m \u001b[43m        \u001b[49m\u001b[43mendpoint\u001b[49m\u001b[43m=\u001b[49m\u001b[43mendpoint\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1034\u001b[39m \u001b[43m        \u001b[49m\u001b[43metag_timeout\u001b[49m\u001b[43m=\u001b[49m\u001b[43metag_timeout\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1035\u001b[39m \u001b[43m        \u001b[49m\u001b[43mheaders\u001b[49m\u001b[43m=\u001b[49m\u001b[43mhf_headers\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1036\u001b[39m \u001b[43m        \u001b[49m\u001b[43mtoken\u001b[49m\u001b[43m=\u001b[49m\u001b[43mtoken\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1037\u001b[39m \u001b[43m        \u001b[49m\u001b[38;5;66;43;03m# Additional options\u001b[39;49;00m\n\u001b[32m   1038\u001b[39m \u001b[43m        \u001b[49m\u001b[43mlocal_files_only\u001b[49m\u001b[43m=\u001b[49m\u001b[43mlocal_files_only\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1039\u001b[39m \u001b[43m        \u001b[49m\u001b[43mforce_download\u001b[49m\u001b[43m=\u001b[49m\u001b[43mforce_download\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1040\u001b[39m \u001b[43m        \u001b[49m\u001b[43mtqdm_class\u001b[49m\u001b[43m=\u001b[49m\u001b[43mtqdm_class\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1041\u001b[39m \u001b[43m        \u001b[49m\u001b[43mdry_run\u001b[49m\u001b[43m=\u001b[49m\u001b[43mdry_run\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1042\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/code/aimakerspace/02_Dense_Vector_Retrieval/.venv/lib/python3.13/site-packages/huggingface_hub/file_download.py:1157\u001b[39m, in \u001b[36m_hf_hub_download_to_cache_dir\u001b[39m\u001b[34m(cache_dir, repo_id, filename, repo_type, revision, endpoint, etag_timeout, headers, token, local_files_only, force_download, tqdm_class, dry_run)\u001b[39m\n\u001b[32m   1151\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(head_call_error, _DEFAULT_RETRY_ON_EXCEPTIONS) \u001b[38;5;129;01mor\u001b[39;00m (\n\u001b[32m   1152\u001b[39m         \u001b[38;5;28misinstance\u001b[39m(head_call_error, HfHubHTTPError)\n\u001b[32m   1153\u001b[39m         \u001b[38;5;129;01mand\u001b[39;00m head_call_error.response.status_code \u001b[38;5;129;01min\u001b[39;00m _DEFAULT_RETRY_ON_STATUS_CODES\n\u001b[32m   1154\u001b[39m     ):\n\u001b[32m   1155\u001b[39m         logger.info(\u001b[33m\"\u001b[39m\u001b[33mNo local file found. Retrying..\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m   1156\u001b[39m         (url_to_download, etag, commit_hash, expected_size, xet_file_data, head_call_error) = (\n\u001b[32m-> \u001b[39m\u001b[32m1157\u001b[39m             \u001b[43m_get_metadata_or_catch_error\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m   1158\u001b[39m \u001b[43m                \u001b[49m\u001b[43mrepo_id\u001b[49m\u001b[43m=\u001b[49m\u001b[43mrepo_id\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1159\u001b[39m \u001b[43m                \u001b[49m\u001b[43mfilename\u001b[49m\u001b[43m=\u001b[49m\u001b[43mfilename\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1160\u001b[39m \u001b[43m                \u001b[49m\u001b[43mrepo_type\u001b[49m\u001b[43m=\u001b[49m\u001b[43mrepo_type\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1161\u001b[39m \u001b[43m                \u001b[49m\u001b[43mrevision\u001b[49m\u001b[43m=\u001b[49m\u001b[43mrevision\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1162\u001b[39m \u001b[43m                \u001b[49m\u001b[43mendpoint\u001b[49m\u001b[43m=\u001b[49m\u001b[43mendpoint\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1163\u001b[39m \u001b[43m                \u001b[49m\u001b[43metag_timeout\u001b[49m\u001b[43m=\u001b[49m\u001b[43m_ETAG_RETRY_TIMEOUT\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1164\u001b[39m \u001b[43m                \u001b[49m\u001b[43mheaders\u001b[49m\u001b[43m=\u001b[49m\u001b[43mheaders\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1165\u001b[39m \u001b[43m                \u001b[49m\u001b[43mtoken\u001b[49m\u001b[43m=\u001b[49m\u001b[43mtoken\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1166\u001b[39m \u001b[43m                \u001b[49m\u001b[43mlocal_files_only\u001b[49m\u001b[43m=\u001b[49m\u001b[43mlocal_files_only\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1167\u001b[39m \u001b[43m                \u001b[49m\u001b[43mstorage_folder\u001b[49m\u001b[43m=\u001b[49m\u001b[43mstorage_folder\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1168\u001b[39m \u001b[43m                \u001b[49m\u001b[43mrelative_filename\u001b[49m\u001b[43m=\u001b[49m\u001b[43mrelative_filename\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1169\u001b[39m \u001b[43m                \u001b[49m\u001b[43mretry_on_errors\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[32m   1170\u001b[39m \u001b[43m            \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1171\u001b[39m         )\n\u001b[32m   1173\u001b[39m \u001b[38;5;66;03m# If still error, raise\u001b[39;00m\n\u001b[32m   1174\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m head_call_error \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/code/aimakerspace/02_Dense_Vector_Retrieval/.venv/lib/python3.13/site-packages/huggingface_hub/file_download.py:1691\u001b[39m, in \u001b[36m_get_metadata_or_catch_error\u001b[39m\u001b[34m(repo_id, filename, repo_type, revision, endpoint, etag_timeout, headers, token, local_files_only, relative_filename, storage_folder, retry_on_errors)\u001b[39m\n\u001b[32m   1689\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m   1690\u001b[39m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m1691\u001b[39m         metadata = \u001b[43mget_hf_file_metadata\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m   1692\u001b[39m \u001b[43m            \u001b[49m\u001b[43murl\u001b[49m\u001b[43m=\u001b[49m\u001b[43murl\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1693\u001b[39m \u001b[43m            \u001b[49m\u001b[43mtimeout\u001b[49m\u001b[43m=\u001b[49m\u001b[43metag_timeout\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1694\u001b[39m \u001b[43m            \u001b[49m\u001b[43mheaders\u001b[49m\u001b[43m=\u001b[49m\u001b[43mheaders\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1695\u001b[39m \u001b[43m            \u001b[49m\u001b[43mtoken\u001b[49m\u001b[43m=\u001b[49m\u001b[43mtoken\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1696\u001b[39m \u001b[43m            \u001b[49m\u001b[43mendpoint\u001b[49m\u001b[43m=\u001b[49m\u001b[43mendpoint\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1697\u001b[39m \u001b[43m            \u001b[49m\u001b[43mretry_on_errors\u001b[49m\u001b[43m=\u001b[49m\u001b[43mretry_on_errors\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1698\u001b[39m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1699\u001b[39m     \u001b[38;5;28;01mexcept\u001b[39;00m RemoteEntryNotFoundError \u001b[38;5;28;01mas\u001b[39;00m http_error:\n\u001b[32m   1700\u001b[39m         \u001b[38;5;28;01mif\u001b[39;00m storage_folder \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m relative_filename \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[32m   1701\u001b[39m             \u001b[38;5;66;03m# Cache the non-existence of the file\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/code/aimakerspace/02_Dense_Vector_Retrieval/.venv/lib/python3.13/site-packages/huggingface_hub/utils/_validators.py:89\u001b[39m, in \u001b[36mvalidate_hf_hub_args.<locals>._inner_fn\u001b[39m\u001b[34m(*args, **kwargs)\u001b[39m\n\u001b[32m     85\u001b[39m         validate_repo_id(arg_value)\n\u001b[32m     87\u001b[39m kwargs = smoothly_deprecate_legacy_arguments(fn_name=fn.\u001b[34m__name__\u001b[39m, kwargs=kwargs)\n\u001b[32m---> \u001b[39m\u001b[32m89\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfn\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/code/aimakerspace/02_Dense_Vector_Retrieval/.venv/lib/python3.13/site-packages/huggingface_hub/file_download.py:1614\u001b[39m, in \u001b[36mget_hf_file_metadata\u001b[39m\u001b[34m(url, token, timeout, library_name, library_version, user_agent, headers, endpoint, retry_on_errors)\u001b[39m\n\u001b[32m   1611\u001b[39m hf_headers[\u001b[33m\"\u001b[39m\u001b[33mAccept-Encoding\u001b[39m\u001b[33m\"\u001b[39m] = \u001b[33m\"\u001b[39m\u001b[33midentity\u001b[39m\u001b[33m\"\u001b[39m  \u001b[38;5;66;03m# prevent any compression => we want to know the real size of the file\u001b[39;00m\n\u001b[32m   1613\u001b[39m \u001b[38;5;66;03m# Retrieve metadata\u001b[39;00m\n\u001b[32m-> \u001b[39m\u001b[32m1614\u001b[39m response = \u001b[43m_httpx_follow_relative_redirects\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m   1615\u001b[39m \u001b[43m    \u001b[49m\u001b[43mmethod\u001b[49m\u001b[43m=\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mHEAD\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43murl\u001b[49m\u001b[43m=\u001b[49m\u001b[43murl\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mheaders\u001b[49m\u001b[43m=\u001b[49m\u001b[43mhf_headers\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtimeout\u001b[49m\u001b[43m=\u001b[49m\u001b[43mtimeout\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mretry_on_errors\u001b[49m\u001b[43m=\u001b[49m\u001b[43mretry_on_errors\u001b[49m\n\u001b[32m   1616\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1617\u001b[39m hf_raise_for_status(response)\n\u001b[32m   1619\u001b[39m \u001b[38;5;66;03m# Return\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/code/aimakerspace/02_Dense_Vector_Retrieval/.venv/lib/python3.13/site-packages/huggingface_hub/file_download.py:302\u001b[39m, in \u001b[36m_httpx_follow_relative_redirects\u001b[39m\u001b[34m(method, url, retry_on_errors, **httpx_kwargs)\u001b[39m\n\u001b[32m    297\u001b[39m no_retry_kwargs: \u001b[38;5;28mdict\u001b[39m[\u001b[38;5;28mstr\u001b[39m, Any] = (\n\u001b[32m    298\u001b[39m     {} \u001b[38;5;28;01mif\u001b[39;00m retry_on_errors \u001b[38;5;28;01melse\u001b[39;00m {\u001b[33m\"\u001b[39m\u001b[33mretry_on_exceptions\u001b[39m\u001b[33m\"\u001b[39m: (), \u001b[33m\"\u001b[39m\u001b[33mretry_on_status_codes\u001b[39m\u001b[33m\"\u001b[39m: ()}\n\u001b[32m    299\u001b[39m )\n\u001b[32m    301\u001b[39m \u001b[38;5;28;01mwhile\u001b[39;00m \u001b[38;5;28;01mTrue\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m302\u001b[39m     response = \u001b[43mhttp_backoff\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    303\u001b[39m \u001b[43m        \u001b[49m\u001b[43mmethod\u001b[49m\u001b[43m=\u001b[49m\u001b[43mmethod\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    304\u001b[39m \u001b[43m        \u001b[49m\u001b[43murl\u001b[49m\u001b[43m=\u001b[49m\u001b[43murl\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    305\u001b[39m \u001b[43m        \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mhttpx_kwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    306\u001b[39m \u001b[43m        \u001b[49m\u001b[43mfollow_redirects\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[32m    307\u001b[39m \u001b[43m        \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mno_retry_kwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    308\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    309\u001b[39m     hf_raise_for_status(response)\n\u001b[32m    311\u001b[39m     \u001b[38;5;66;03m# Check if response is a relative redirect\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/code/aimakerspace/02_Dense_Vector_Retrieval/.venv/lib/python3.13/site-packages/huggingface_hub/utils/_http.py:506\u001b[39m, in \u001b[36mhttp_backoff\u001b[39m\u001b[34m(method, url, max_retries, base_wait_time, max_wait_time, retry_on_exceptions, retry_on_status_codes, **kwargs)\u001b[39m\n\u001b[32m    441\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mhttp_backoff\u001b[39m(\n\u001b[32m    442\u001b[39m     method: HTTP_METHOD_T,\n\u001b[32m    443\u001b[39m     url: \u001b[38;5;28mstr\u001b[39m,\n\u001b[32m   (...)\u001b[39m\u001b[32m    450\u001b[39m     **kwargs,\n\u001b[32m    451\u001b[39m ) -> httpx.Response:\n\u001b[32m    452\u001b[39m \u001b[38;5;250m    \u001b[39m\u001b[33;03m\"\"\"Wrapper around httpx to retry calls on an endpoint, with exponential backoff.\u001b[39;00m\n\u001b[32m    453\u001b[39m \n\u001b[32m    454\u001b[39m \u001b[33;03m    Endpoint call is retried on exceptions (ex: connection timeout, proxy error,...)\u001b[39;00m\n\u001b[32m   (...)\u001b[39m\u001b[32m    504\u001b[39m \u001b[33;03m    > issue on [Github](https://github.com/huggingface/huggingface_hub).\u001b[39;00m\n\u001b[32m    505\u001b[39m \u001b[33;03m    \"\"\"\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m506\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mnext\u001b[39;49m\u001b[43m(\u001b[49m\n\u001b[32m    507\u001b[39m \u001b[43m        \u001b[49m\u001b[43m_http_backoff_base\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    508\u001b[39m \u001b[43m            \u001b[49m\u001b[43mmethod\u001b[49m\u001b[43m=\u001b[49m\u001b[43mmethod\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    509\u001b[39m \u001b[43m            \u001b[49m\u001b[43murl\u001b[49m\u001b[43m=\u001b[49m\u001b[43murl\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    510\u001b[39m \u001b[43m            \u001b[49m\u001b[43mmax_retries\u001b[49m\u001b[43m=\u001b[49m\u001b[43mmax_retries\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    511\u001b[39m \u001b[43m            \u001b[49m\u001b[43mbase_wait_time\u001b[49m\u001b[43m=\u001b[49m\u001b[43mbase_wait_time\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    512\u001b[39m \u001b[43m            \u001b[49m\u001b[43mmax_wait_time\u001b[49m\u001b[43m=\u001b[49m\u001b[43mmax_wait_time\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    513\u001b[39m \u001b[43m            \u001b[49m\u001b[43mretry_on_exceptions\u001b[49m\u001b[43m=\u001b[49m\u001b[43mretry_on_exceptions\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    514\u001b[39m \u001b[43m            \u001b[49m\u001b[43mretry_on_status_codes\u001b[49m\u001b[43m=\u001b[49m\u001b[43mretry_on_status_codes\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    515\u001b[39m \u001b[43m            \u001b[49m\u001b[43mstream\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[32m    516\u001b[39m \u001b[43m            \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    517\u001b[39m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    518\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/code/aimakerspace/02_Dense_Vector_Retrieval/.venv/lib/python3.13/site-packages/huggingface_hub/utils/_http.py:414\u001b[39m, in \u001b[36m_http_backoff_base\u001b[39m\u001b[34m(method, url, max_retries, base_wait_time, max_wait_time, retry_on_exceptions, retry_on_status_codes, stream, **kwargs)\u001b[39m\n\u001b[32m    412\u001b[39m             \u001b[38;5;28;01mreturn\u001b[39;00m\n\u001b[32m    413\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m414\u001b[39m     response = \u001b[43mclient\u001b[49m\u001b[43m.\u001b[49m\u001b[43mrequest\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmethod\u001b[49m\u001b[43m=\u001b[49m\u001b[43mmethod\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43murl\u001b[49m\u001b[43m=\u001b[49m\u001b[43murl\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    415\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m _should_retry(response):\n\u001b[32m    416\u001b[39m         \u001b[38;5;28;01myield\u001b[39;00m response\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/code/aimakerspace/02_Dense_Vector_Retrieval/.venv/lib/python3.13/site-packages/httpx/_client.py:825\u001b[39m, in \u001b[36mClient.request\u001b[39m\u001b[34m(self, method, url, content, data, files, json, params, headers, cookies, auth, follow_redirects, timeout, extensions)\u001b[39m\n\u001b[32m    810\u001b[39m     warnings.warn(message, \u001b[38;5;167;01mDeprecationWarning\u001b[39;00m, stacklevel=\u001b[32m2\u001b[39m)\n\u001b[32m    812\u001b[39m request = \u001b[38;5;28mself\u001b[39m.build_request(\n\u001b[32m    813\u001b[39m     method=method,\n\u001b[32m    814\u001b[39m     url=url,\n\u001b[32m   (...)\u001b[39m\u001b[32m    823\u001b[39m     extensions=extensions,\n\u001b[32m    824\u001b[39m )\n\u001b[32m--> \u001b[39m\u001b[32m825\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43msend\u001b[49m\u001b[43m(\u001b[49m\u001b[43mrequest\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mauth\u001b[49m\u001b[43m=\u001b[49m\u001b[43mauth\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfollow_redirects\u001b[49m\u001b[43m=\u001b[49m\u001b[43mfollow_redirects\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/code/aimakerspace/02_Dense_Vector_Retrieval/.venv/lib/python3.13/site-packages/httpx/_client.py:901\u001b[39m, in \u001b[36mClient.send\u001b[39m\u001b[34m(self, request, stream, auth, follow_redirects)\u001b[39m\n\u001b[32m    887\u001b[39m \u001b[38;5;250m\u001b[39m\u001b[33;03m\"\"\"\u001b[39;00m\n\u001b[32m    888\u001b[39m \u001b[33;03mSend a request.\u001b[39;00m\n\u001b[32m    889\u001b[39m \n\u001b[32m   (...)\u001b[39m\u001b[32m    898\u001b[39m \u001b[33;03m[0]: /advanced/clients/#request-instances\u001b[39;00m\n\u001b[32m    899\u001b[39m \u001b[33;03m\"\"\"\u001b[39;00m\n\u001b[32m    900\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m._state == ClientState.CLOSED:\n\u001b[32m--> \u001b[39m\u001b[32m901\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mRuntimeError\u001b[39;00m(\u001b[33m\"\u001b[39m\u001b[33mCannot send a request, as the client has been closed.\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m    903\u001b[39m \u001b[38;5;28mself\u001b[39m._state = ClientState.OPENED\n\u001b[32m    904\u001b[39m follow_redirects = (\n\u001b[32m    905\u001b[39m     \u001b[38;5;28mself\u001b[39m.follow_redirects\n\u001b[32m    906\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(follow_redirects, UseClientDefault)\n\u001b[32m    907\u001b[39m     \u001b[38;5;28;01melse\u001b[39;00m follow_redirects\n\u001b[32m    908\u001b[39m )\n",
      "\u001b[31mRuntimeError\u001b[39m: Cannot send a request, as the client has been closed."
     ]
    }
   ],
   "source": [
    "from sentence_transformers import SentenceTransformer\n",
    "\n",
    "# Initialize the model - this will download it on first run\n",
    "embedding_model = SentenceTransformer('sentence-transformers/all-MiniLM-L6-v2')\n",
    "\n",
    "print(f\"Model loaded: {embedding_model}\")\n",
    "print(f\"Max sequence length: {embedding_model.max_seq_length}\")\n",
    "print(f\"Embedding dimension: {embedding_model.get_sentence_embedding_dimension()}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's define our two sentences:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "puppy_sentence = \"i love puppies\"\n",
    "dog_sentence = \"i love dogs\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we can convert those into embedding vectors using HuggingFace!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "puppy_vector = embedding_model.encode(puppy_sentence)\n",
    "dog_vector = embedding_model.encode(dog_sentence)\n",
    "\n",
    "print(f\"Puppy vector shape: {puppy_vector.shape}\")\n",
    "print(f\"Dog vector shape: {dog_vector.shape}\")\n",
    "print(f\"\\nFirst 10 dimensions of puppy vector: {puppy_vector[:10]}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we can determine how closely they are related using our distance measure!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "similarity = cosine_similarity(puppy_vector, dog_vector)\n",
    "print(f\"Cosine similarity between 'i love puppies' and 'i love dogs': {similarity}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Remember, with cosine similarity, close to 1. means they're very close!\n",
    "\n",
    "Let's see what happens if we use a different set of sentences."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "puppy_sentence = \"I love puppies!\"\n",
    "cat_sentence = \"I dislike cats!\"\n",
    "\n",
    "puppy_vector = embedding_model.encode(puppy_sentence)\n",
    "cat_vector = embedding_model.encode(cat_sentence)\n",
    "\n",
    "similarity = cosine_similarity(puppy_vector, cat_vector)\n",
    "print(f\"Cosine similarity between 'I love puppies!' and 'I dislike cats!': {similarity}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As you can see - these vectors are further apart - as expected!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Embedding Vector Calculations\n",
    "\n",
    "One of the ways that Embedding Vectors can be leveraged, and a fun \"proof\" that they work the way we expected can be explored via \"Vector Calculations\"\n",
    "\n",
    "That is to say: If we take the vector for \"King\", and subtract the vector for \"man\", and add the vector for \"woman\" - we should have a vector that is similar to \"Queen\".\n",
    "\n",
    "Let's try this out below!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "king_vector = np.array(embedding_model.encode(\"King\"))\n",
    "man_vector = np.array(embedding_model.encode(\"man\"))\n",
    "woman_vector = np.array(embedding_model.encode(\"woman\"))\n",
    "\n",
    "vector_calculation_result = king_vector - man_vector + woman_vector\n",
    "\n",
    "queen_vector = np.array(embedding_model.encode(\"Queen\"))\n",
    "\n",
    "similarity = cosine_similarity(vector_calculation_result, queen_vector)\n",
    "print(f\"Cosine similarity between (King - man + woman) and Queen: {similarity}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As you can see - the resulting vector is indeed quite close to the \"Queen\" vector!\n",
    "\n",
    "> NOTE: The loss is explained by the vectors not *literally* encoding information along axes as simple as \"man\" or \"woman\"."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Batch Processing\n",
    "\n",
    "One of the great features of sentence-transformers is efficient batch processing. Let's see how we can embed multiple sentences at once:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sentences = [\n",
    "    \"The cat sits on the mat\",\n",
    "    \"A feline rests on the rug\",\n",
    "    \"Dogs are loyal companions\",\n",
    "    \"The weather is sunny today\",\n",
    "    \"It's a beautiful day outside\"\n",
    "]\n",
    "\n",
    "# Encode all sentences at once\n",
    "embeddings = embedding_model.encode(sentences)\n",
    "\n",
    "print(f\"Encoded {len(sentences)} sentences\")\n",
    "print(f\"Embeddings shape: {embeddings.shape}\")\n",
    "print(\"\\nSimilarities:\")\n",
    "print(f\"Cat/mat vs Feline/rug: {cosine_similarity(embeddings[0], embeddings[1]):.4f}\")\n",
    "print(f\"Cat/mat vs Dogs: {cosine_similarity(embeddings[0], embeddings[2]):.4f}\")\n",
    "print(f\"Weather sentences: {cosine_similarity(embeddings[3], embeddings[4]):.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Performance Comparison\n",
    "\n",
    "Let's see how fast the local HuggingFace model is for embedding text:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "\n",
    "# Test single embedding\n",
    "text = \"This is a test sentence for measuring embedding speed.\"\n",
    "\n",
    "start = time.time()\n",
    "for _ in range(100):\n",
    "    embedding = embedding_model.encode(text)\n",
    "end = time.time()\n",
    "\n",
    "print(f\"Average time per embedding (single): {(end - start) / 100 * 1000:.2f}ms\")\n",
    "\n",
    "# Test batch embedding\n",
    "texts = [f\"This is test sentence number {i}\" for i in range(100)]\n",
    "\n",
    "start = time.time()\n",
    "embeddings = embedding_model.encode(texts)\n",
    "end = time.time()\n",
    "\n",
    "print(f\"Time for batch of 100: {(end - start) * 1000:.2f}ms\")\n",
    "print(f\"Average time per embedding (batch): {(end - start) / 100 * 1000:.2f}ms\")\n",
    "print(\"\\nBatch processing is much more efficient!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Advantages of Using HuggingFace Models\n",
    "\n",
    "1. **No API Key Required**: No need to manage API keys or worry about rate limits\n",
    "2. **Free**: Completely free to use, no per-token costs\n",
    "3. **Privacy**: Your data never leaves your machine\n",
    "4. **Offline**: Works without internet (after initial model download)\n",
    "5. **Speed**: Can be very fast, especially with GPU acceleration\n",
    "6. **Smaller Vectors**: 384 dimensions vs OpenAI's 1536 means less storage and faster comparisons\n",
    "7. **Open Source**: Full transparency in model architecture and training\n",
    "\n",
    "### Considerations\n",
    "\n",
    "1. **Initial Download**: ~90MB model download on first use\n",
    "2. **Hardware Dependent**: Performance depends on your CPU/GPU\n",
    "3. **Dimension Differences**: Cannot mix embeddings from different models\n",
    "4. **Max Length**: 256 word pieces (vs OpenAI's 8191 tokens)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Using GPU Acceleration (Optional)\n",
    "\n",
    "If you have a CUDA-capable GPU, you can significantly speed up embeddings:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "\n",
    "# Check if CUDA is available\n",
    "print(f\"CUDA available: {torch.cuda.is_available()}\")\n",
    "if torch.cuda.is_available():\n",
    "    print(f\"CUDA device: {torch.cuda.get_device_name(0)}\")\n",
    "    \n",
    "    # Move model to GPU\n",
    "    embedding_model = embedding_model.to('cuda')\n",
    "    print(\"Model moved to GPU!\")\n",
    "else:\n",
    "    print(\"Running on CPU\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Conclusion\n",
    "\n",
    "As you can see - embeddings can help us convert text into a machine understandable format, which we can leverage for a number of purposes.\n",
    "\n",
    "HuggingFace's sentence-transformers library provides an excellent, free, and privacy-preserving alternative to proprietary embedding APIs. The `all-MiniLM-L6-v2` model offers:\n",
    "\n",
    "- Strong performance for semantic search and similarity tasks\n",
    "- Smaller embedding dimensions (384 vs 1536) for efficient storage\n",
    "- Local processing without any external API dependencies\n",
    "- Fast inference, especially with batch processing or GPU acceleration\n",
    "\n",
    "This makes it an excellent choice for learning about embeddings and building RAG applications!"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "02-embeddings-and-rag",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}