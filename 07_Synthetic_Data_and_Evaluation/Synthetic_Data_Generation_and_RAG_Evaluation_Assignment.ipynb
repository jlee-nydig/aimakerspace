{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Module 7: Synthetic Data Generation and RAG Evaluation with Ragas\n",
    "\n",
    "In this notebook, we'll go end-to-end from **generating synthetic evaluation data** to **systematically evaluating and improving a RAG pipeline** ‚Äî all using [Ragas](https://github.com/explodinggradients/ragas).\n",
    "\n",
    "The flow is:\n",
    "1. **Generate** synthetic test data using Ragas' knowledge graph-based approach\n",
    "2. **Build** a baseline RAG application with LangChain and LangGraph\n",
    "3. **Evaluate** the RAG application against our synthetic test set using Ragas metrics\n",
    "4. **Iterate** on the pipeline and measure the impact\n",
    "\n",
    "> **NOTE:** Ragas is framework-agnostic ‚Äî while this example uses LangChain/LangGraph, you can use Ragas with any framework (or none at all). Ragas is best suited for finding *directional* changes in your LLM-based systems. The absolute scores aren't comparable in a vacuum.\n",
    "\n",
    "## Outline\n",
    "\n",
    "**Part 1: Synthetic Data Generation**\n",
    "- Task 1: Dependencies and API Keys\n",
    "- Task 2: Data Preparation\n",
    "- Task 3: Knowledge Graph Construction\n",
    "- Task 4: Generating Synthetic Test Data\n",
    "- ***‚ùì Question #1 & Question #2***\n",
    "- ***üèóÔ∏è Activity #1: Custom Query Distribution***\n",
    "\n",
    "**Part 2: RAG Evaluation with Ragas**\n",
    "- Task 5: Building a Baseline RAG Application\n",
    "- Task 6: Evaluating with Ragas\n",
    "- Task 7: Making Adjustments and Re-Evaluating\n",
    "- ***‚ùì Question #3, Question #4, Question #5, & Question #6***\n",
    "- ***üèóÔ∏è Activity #2: Implement a Different Reranking Strategy***"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "# Part 1: Synthetic Data Generation with Ragas\n",
    "\n",
    "Before we can evaluate a RAG system, we need high-quality test data. Manually creating question-answer pairs is time-consuming and often biased toward simple queries. Ragas solves this by building a **knowledge graph** from your documents and using it to generate diverse, realistic test questions automatically.\n",
    "\n",
    "We'll use the **Stone Ridge 2025 Investor Letter** and an **Alternative Investments Handbook** as our source documents ‚Äî maintaining continuity with the investment advisory use case from previous sessions."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Task 1: Dependencies and API Keys\n",
    "\n",
    "If you have not already done so, install the required libraries using the uv package manager:\n",
    "```bash\n",
    "uv sync\n",
    "```\n",
    "\n",
    "We'll need API keys for:\n",
    "- **OpenAI** ‚Äî for LLM and embedding models (used in both SDG and RAG evaluation)\n",
    "- **Cohere** ‚Äî for reranking in the improved pipeline ([sign up here](https://docs.cohere.com/reference/about))\n",
    "\n",
    "You have two options for supplying your API keys:\n",
    "- Use environment variables (copy `.env.sample` to `.env` and fill in your keys)\n",
    "- Provide them via the prompts below"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import nest_asyncio\n",
    "nest_asyncio.apply()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to /Users/jaden.lee/nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "[nltk_data] Downloading package averaged_perceptron_tagger to\n",
      "[nltk_data]     /Users/jaden.lee/nltk_data...\n",
      "[nltk_data]   Package averaged_perceptron_tagger is already up-to-\n",
      "[nltk_data]       date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import nltk\n",
    "nltk.download('punkt')\n",
    "nltk.download('averaged_perceptron_tagger')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from getpass import getpass\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "load_dotenv()\n",
    "\n",
    "if not os.environ.get(\"OPENAI_API_KEY\"):\n",
    "    os.environ[\"OPENAI_API_KEY\"] = getpass(\"Please enter your OpenAI API key!\")\n",
    "\n",
    "if not os.environ.get(\"COHERE_API_KEY\"):\n",
    "    os.environ[\"COHERE_API_KEY\"] = getpass(\"Please enter your Cohere API key!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Task 2: Data Preparation\n",
    "\n",
    "We'll prepare our data using two complementary investment-focused sources:\n",
    "- **Stone Ridge 2025 Investor Letter** ‚Äî covering Stone Ridge's investment philosophy, Bayesian approach to decision-making, energy investments, reinsurance, and risk management\n",
    "- **Alternative Investments Handbook** ‚Äî covering alternative asset classes including real estate, private equity, hedge funds, reinsurance, commodities, and infrastructure\n",
    "\n",
    "The topical overlap between these documents (particularly around reinsurance, risk premiums, diversification, and alternative investments) helps Ragas build rich cross-document relationships in the knowledge graph."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded 15 documents:\n",
      "  - Stone Ridge 2025 Investor Letter: 14 pages\n",
      "  - AlternativeInvestmentsHandbook.txt: 1 document(s)\n"
     ]
    }
   ],
   "source": [
    "from langchain_community.document_loaders import PyMuPDFLoader, TextLoader\n",
    "\n",
    "# Load the Stone Ridge 2025 Investor Letter (PDF)\n",
    "pdf_loader = PyMuPDFLoader(\"data/Stone Ridge 2025 Investor Letter.pdf\")\n",
    "pdf_docs = pdf_loader.load()\n",
    "\n",
    "# Load the Alternative Investments Handbook (text)\n",
    "txt_loader = TextLoader(\"data/AlternativeInvestmentsHandbook.txt\")\n",
    "txt_docs = txt_loader.load()\n",
    "\n",
    "# Combine into a single list\n",
    "docs = pdf_docs + txt_docs\n",
    "print(f\"Loaded {len(docs)} documents:\")\n",
    "print(f\"  - Stone Ridge 2025 Investor Letter: {len(pdf_docs)} pages\")\n",
    "print(f\"  - AlternativeInvestmentsHandbook.txt: {len(txt_docs)} document(s)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Task 3: Knowledge Graph Construction\n",
    "\n",
    "Ragas uses a **knowledge graph-based approach** to create synthetic test data. This is powerful because it allows us to create complex, multi-hop queries ‚Äî not just simple factoid questions. Systems tend to perform well on simple evaluation tasks, so this additional complexity helps us find real weaknesses.\n",
    "\n",
    "The process works in three stages:\n",
    "1. **Build the graph** ‚Äî insert documents as nodes\n",
    "2. **Apply transformations** ‚Äî extract headlines, summaries, themes, entities, and embeddings\n",
    "3. **Create relationships** ‚Äî use cosine similarity and overlap scores to connect related nodes\n",
    "\n",
    "Let's start by defining our `generator_llm` and `generator_embeddings`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "from ragas.llms import LangchainLLMWrapper\n",
    "from ragas.embeddings import LangchainEmbeddingsWrapper\n",
    "from langchain_openai import ChatOpenAI, OpenAIEmbeddings\n",
    "\n",
    "generator_llm = LangchainLLMWrapper(ChatOpenAI(model=\"gpt-4.1-nano\"))\n",
    "generator_embeddings = LangchainEmbeddingsWrapper(OpenAIEmbeddings())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 1: Initialize the Knowledge Graph\n",
    "\n",
    "We create an empty knowledge graph and populate it with our document nodes. Each full document becomes a node of type `DOCUMENT`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import certifi\n",
    "\n",
    "# Create a combined cert bundle with Zscaler for corporate network\n",
    "zscaler_cert = \"/Users/jaden.lee/ZscalerRootCertificate-2048-SHA256-Feb2025.crt\"\n",
    "combined_cert = \"/Users/jaden.lee/combined_certs.pem\"\n",
    "\n",
    "with open(combined_cert, \"w\") as outfile:\n",
    "    with open(certifi.where(), \"r\") as certifi_file:\n",
    "        outfile.write(certifi_file.read())\n",
    "    with open(zscaler_cert, \"r\") as zscaler_file:\n",
    "        outfile.write(zscaler_file.read())\n",
    "\n",
    "os.environ['REQUESTS_CA_BUNDLE'] = combined_cert\n",
    "os.environ['SSL_CERT_FILE'] = combined_cert\n",
    "os.environ['CURL_CA_BUNDLE'] = combined_cert"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "KnowledgeGraph(nodes: 15, relationships: 0)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from ragas.testset.graph import KnowledgeGraph, Node, NodeType\n",
    "\n",
    "kg = KnowledgeGraph()\n",
    "\n",
    "for doc in docs:\n",
    "    kg.nodes.append(\n",
    "        Node(\n",
    "            type=NodeType.DOCUMENT,\n",
    "            properties={\"page_content\": doc.page_content, \"document_metadata\": doc.metadata}\n",
    "        )\n",
    "    )\n",
    "kg"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 2: Apply Transformations\n",
    "\n",
    "Now we apply the [default transformations](https://docs.ragas.io/en/latest/references/transforms/#ragas.testset.transforms.default_transforms) to enrich our knowledge graph. These transformations:\n",
    "\n",
    "- **HeadlinesExtractor** ‚Äî finds the overall headlines for each document\n",
    "- **SummaryExtractor** ‚Äî produces summaries of the documents\n",
    "- **ThemesExtractor** ‚Äî extracts broad themes\n",
    "- **EmbeddingExtractor** ‚Äî creates embeddings for similarity computation\n",
    "- **NERExtractor** ‚Äî extracts named entities\n",
    "\n",
    "These are then used to build relationships between nodes via cosine similarity and overlap scoring."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "22dd6afdcfa4421fb3939df2a66d9652",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Applying HeadlinesExtractor:   0%|          | 0/14 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "853eb2eb743d4210b49e421a7733c2f5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Applying HeadlineSplitter:   0%|          | 0/15 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "unable to apply transformation: 'headlines' property not found in this node\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8c0000da8db34b8c88827b1d6b23e3e6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Applying SummaryExtractor:   0%|          | 0/25 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Property 'summary' already exists in node '9d6b55'. Skipping!\n",
      "Property 'summary' already exists in node '54f924'. Skipping!\n",
      "Property 'summary' already exists in node 'eec453'. Skipping!\n",
      "Property 'summary' already exists in node '72a600'. Skipping!\n",
      "Property 'summary' already exists in node '40931f'. Skipping!\n",
      "Property 'summary' already exists in node '470328'. Skipping!\n",
      "Property 'summary' already exists in node '800089'. Skipping!\n",
      "Property 'summary' already exists in node 'f3c680'. Skipping!\n",
      "Property 'summary' already exists in node 'd01f69'. Skipping!\n",
      "Property 'summary' already exists in node '501634'. Skipping!\n",
      "Property 'summary' already exists in node '26c079'. Skipping!\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8e7b82f912854b82ba2a7cb3eea2cbab",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Applying CustomNodeFilter:   0%|          | 0/10 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e23a9f5e4a064c8fad0afaa2fcadcf6e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Applying [EmbeddingExtractor, ThemesExtractor, NERExtractor]:   0%|          | 0/45 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Property 'summary_embedding' already exists in node '9d6b55'. Skipping!\n",
      "Property 'summary_embedding' already exists in node '54f924'. Skipping!\n",
      "Property 'summary_embedding' already exists in node '72a600'. Skipping!\n",
      "Property 'summary_embedding' already exists in node '40931f'. Skipping!\n",
      "Property 'summary_embedding' already exists in node 'eec453'. Skipping!\n",
      "Property 'summary_embedding' already exists in node '800089'. Skipping!\n",
      "Property 'summary_embedding' already exists in node 'd01f69'. Skipping!\n",
      "Property 'summary_embedding' already exists in node '501634'. Skipping!\n",
      "Property 'summary_embedding' already exists in node '470328'. Skipping!\n",
      "Property 'summary_embedding' already exists in node '26c079'. Skipping!\n",
      "Property 'summary_embedding' already exists in node 'f3c680'. Skipping!\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e0228a63139a4729909853e22b37d755",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Applying [CosineSimilarityBuilder, OverlapScoreBuilder]:   0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "KnowledgeGraph(nodes: 36, relationships: 304)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from ragas.testset.transforms import default_transforms, apply_transforms\n",
    "\n",
    "transforms = default_transforms(\n",
    "    documents=docs,\n",
    "    llm=generator_llm,\n",
    "    embedding_model=generator_embeddings\n",
    ")\n",
    "apply_transforms(kg, transforms)\n",
    "kg"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 3: Save the Knowledge Graph\n",
    "\n",
    "Knowledge graphs can be saved and loaded, which is useful for iterating on test generation without rebuilding the graph each time."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "kg.save(\"investment_data_kg.json\")\n",
    "\n",
    "# You can reload it later:\n",
    "# kg = KnowledgeGraph.load(\"investment_data_kg.json\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Task 4: Generating Synthetic Test Data\n",
    "\n",
    "With our knowledge graph built, we can now generate synthetic test data. Ragas provides several **query synthesizers**, each producing a different type of question:\n",
    "\n",
    "- **`SingleHopSpecificQuerySynthesizer`** ‚Äî creates questions answerable from a single chunk of context (e.g., *\"What is Stone Ridge's approach to reinsurance investing?\"*)\n",
    "- **`MultiHopAbstractQuerySynthesizer`** ‚Äî creates questions requiring synthesis across multiple chunks at an abstract level (e.g., *\"How do alternative risk premiums relate to portfolio diversification?\"*)\n",
    "- **`MultiHopSpecificQuerySynthesizer`** ‚Äî creates questions requiring specific details from multiple chunks (e.g., *\"How does Stone Ridge's Bayesian philosophy connect to their energy investment strategy?\"*)\n",
    "\n",
    "We define a **query distribution** to control the mix of question types."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "from ragas.testset.synthesizers import (\n",
    "    SingleHopSpecificQuerySynthesizer,\n",
    "    MultiHopAbstractQuerySynthesizer,\n",
    "    MultiHopSpecificQuerySynthesizer,\n",
    ")\n",
    "\n",
    "query_distribution = [\n",
    "    (SingleHopSpecificQuerySynthesizer(llm=generator_llm), 0.5),\n",
    "    (MultiHopAbstractQuerySynthesizer(llm=generator_llm), 0.25),\n",
    "    (MultiHopSpecificQuerySynthesizer(llm=generator_llm), 0.25),\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "409b9a21cc0143f0a2c7e9d99066a36c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating personas:   0%|          | 0/3 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4a0301d0a1a9411096ac8e781b678088",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating Scenarios:   0%|          | 0/3 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f015f9f755e145fe9c44e5bdcee0ad6d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating Samples:   0%|          | 0/11 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>user_input</th>\n",
       "      <th>reference_contexts</th>\n",
       "      <th>reference</th>\n",
       "      <th>synthesizer_name</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>How has Chicago influenced your career?</td>\n",
       "      <td>[and my career has essentially been a three-de...</td>\n",
       "      <td>My career has essentially been a three-decade ...</td>\n",
       "      <td>single_hop_specifc_query_synthesizer</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>How does Magnetar Capital's approach relate to...</td>\n",
       "      <td>[TODAY‚ÄôS THE DAY Fancy math aside, the foundat...</td>\n",
       "      <td>The context mentions Alec Litowitz, founder of...</td>\n",
       "      <td>single_hop_specifc_query_synthesizer</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Stone Ridge Energy how much return last year a...</td>\n",
       "      <td>[Standardized returns as of most recent quarte...</td>\n",
       "      <td>Standardized returns as of most recent quarter...</td>\n",
       "      <td>single_hop_specifc_query_synthesizer</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>What is Stone Rigde?</td>\n",
       "      <td>[Risk Disclosures This communication has been ...</td>\n",
       "      <td>Stone Ridge is mentioned in the context as par...</td>\n",
       "      <td>single_hop_specifc_query_synthesizer</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>What are commodities in alternative investments?</td>\n",
       "      <td>[The Alternative Investments Handbook A Practi...</td>\n",
       "      <td>Commodities are included as an asset class wit...</td>\n",
       "      <td>single_hop_specifc_query_synthesizer</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Wht factors affect real estate values like loc...</td>\n",
       "      <td>[&lt;1-hop&gt;\\n\\nPART 2: REAL ESTATE INVESTMENTS Ch...</td>\n",
       "      <td>Factors affecting real estate values include l...</td>\n",
       "      <td>multi_hop_abstract_query_synthesizer</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Reinsurance like hurricanes earthquakes storms...</td>\n",
       "      <td>[&lt;1-hop&gt;\\n\\nPART 5: INSURANCE-LINKED INVESTMEN...</td>\n",
       "      <td>Reinsurance is insurance for insurance compani...</td>\n",
       "      <td>multi_hop_abstract_query_synthesizer</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Whi is the importnt of private equity concepts...</td>\n",
       "      <td>[&lt;1-hop&gt;\\n\\nThe Alternative Investments Handbo...</td>\n",
       "      <td>The importance of private equity concepts such...</td>\n",
       "      <td>multi_hop_abstract_query_synthesizer</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Whay hedge fund strategies are used for divers...</td>\n",
       "      <td>[&lt;1-hop&gt;\\n\\nThe Alternative Investments Handbo...</td>\n",
       "      <td>Hedge fund strategies such as long/short equit...</td>\n",
       "      <td>multi_hop_specific_query_synthesizer</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>In Chapter 2 and Chapter 4, how does the real ...</td>\n",
       "      <td>[&lt;1-hop&gt;\\n\\nPART 2: REAL ESTATE INVESTMENTS Ch...</td>\n",
       "      <td>Chapter 4 explains various types of real estat...</td>\n",
       "      <td>multi_hop_specific_query_synthesizer</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>How does PART 2's discussion of real estate as...</td>\n",
       "      <td>[&lt;1-hop&gt;\\n\\nPART 2: REAL ESTATE INVESTMENTS Ch...</td>\n",
       "      <td>PART 2 describes real estate as a widely held ...</td>\n",
       "      <td>multi_hop_specific_query_synthesizer</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                           user_input  \\\n",
       "0             How has Chicago influenced your career?   \n",
       "1   How does Magnetar Capital's approach relate to...   \n",
       "2   Stone Ridge Energy how much return last year a...   \n",
       "3                                What is Stone Rigde?   \n",
       "4    What are commodities in alternative investments?   \n",
       "5   Wht factors affect real estate values like loc...   \n",
       "6   Reinsurance like hurricanes earthquakes storms...   \n",
       "7   Whi is the importnt of private equity concepts...   \n",
       "8   Whay hedge fund strategies are used for divers...   \n",
       "9   In Chapter 2 and Chapter 4, how does the real ...   \n",
       "10  How does PART 2's discussion of real estate as...   \n",
       "\n",
       "                                   reference_contexts  \\\n",
       "0   [and my career has essentially been a three-de...   \n",
       "1   [TODAY‚ÄôS THE DAY Fancy math aside, the foundat...   \n",
       "2   [Standardized returns as of most recent quarte...   \n",
       "3   [Risk Disclosures This communication has been ...   \n",
       "4   [The Alternative Investments Handbook A Practi...   \n",
       "5   [<1-hop>\\n\\nPART 2: REAL ESTATE INVESTMENTS Ch...   \n",
       "6   [<1-hop>\\n\\nPART 5: INSURANCE-LINKED INVESTMEN...   \n",
       "7   [<1-hop>\\n\\nThe Alternative Investments Handbo...   \n",
       "8   [<1-hop>\\n\\nThe Alternative Investments Handbo...   \n",
       "9   [<1-hop>\\n\\nPART 2: REAL ESTATE INVESTMENTS Ch...   \n",
       "10  [<1-hop>\\n\\nPART 2: REAL ESTATE INVESTMENTS Ch...   \n",
       "\n",
       "                                            reference  \\\n",
       "0   My career has essentially been a three-decade ...   \n",
       "1   The context mentions Alec Litowitz, founder of...   \n",
       "2   Standardized returns as of most recent quarter...   \n",
       "3   Stone Ridge is mentioned in the context as par...   \n",
       "4   Commodities are included as an asset class wit...   \n",
       "5   Factors affecting real estate values include l...   \n",
       "6   Reinsurance is insurance for insurance compani...   \n",
       "7   The importance of private equity concepts such...   \n",
       "8   Hedge fund strategies such as long/short equit...   \n",
       "9   Chapter 4 explains various types of real estat...   \n",
       "10  PART 2 describes real estate as a widely held ...   \n",
       "\n",
       "                        synthesizer_name  \n",
       "0   single_hop_specifc_query_synthesizer  \n",
       "1   single_hop_specifc_query_synthesizer  \n",
       "2   single_hop_specifc_query_synthesizer  \n",
       "3   single_hop_specifc_query_synthesizer  \n",
       "4   single_hop_specifc_query_synthesizer  \n",
       "5   multi_hop_abstract_query_synthesizer  \n",
       "6   multi_hop_abstract_query_synthesizer  \n",
       "7   multi_hop_abstract_query_synthesizer  \n",
       "8   multi_hop_specific_query_synthesizer  \n",
       "9   multi_hop_specific_query_synthesizer  \n",
       "10  multi_hop_specific_query_synthesizer  "
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from ragas.testset import TestsetGenerator\n",
    "\n",
    "generator = TestsetGenerator(\n",
    "    llm=generator_llm,\n",
    "    embedding_model=generator_embeddings,\n",
    "    knowledge_graph=kg\n",
    ")\n",
    "\n",
    "testset = generator.generate(testset_size=10, query_distribution=query_distribution)\n",
    "testset.to_pandas()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Abstracted SDG (Shortcut)\n",
    "\n",
    "The above was the **unrolled** process showing each step. Ragas also provides a one-liner that builds the knowledge graph under the hood and generates the test set in a single call. This is convenient for quick iteration:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Abstracted approach (for reference):\n",
    "# generator = TestsetGenerator(llm=generator_llm, embedding_model=generator_embeddings)\n",
    "# dataset = generator.generate_with_langchain_docs(docs, testset_size=10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ‚ùì Question #1:\n",
    "\n",
    "What are the three types of query synthesizers doing? Describe each one in simple terms.\n",
    "\n",
    "##### ‚úÖ Answer:\n",
    "\n",
    "SingleHopSpecificQuerySynthesizer - creates simple, straightforward questions that can be answered using information from a single chunk of the document\n",
    "MultiHopAbstractQuerySynthesizer - creates questions that require combining information from multiple chunks at a conceptual/abstract level. You need to synthesize ideas across different parts of the documents.\n",
    "MultiHopSpecificQuerySynthesizer - creates questions that require combining specific details from multiple chunks. Similar to MultiHopAbstract, but focuses on specific facts rather than abstract concepts."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ‚ùì Question #2:\n",
    "\n",
    "Ragas offers both an \"unrolled\" (manual) approach and an \"abstracted\" (automatic) approach to synthetic data generation. What are the trade-offs between these two approaches? When would you choose one over the other?\n",
    "\n",
    "##### ‚úÖ Answer:\n",
    "\n",
    "I believe the main trade offs are specification and control. With abstract, you are giving up control and customization for simplification and ease of use. I would choose unrolled when I need to make a lot of customizations and the tests need to be specific for production deployment."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### üèóÔ∏è Activity #1: Custom Query Distribution\n",
    "\n",
    "Modify the `query_distribution` to experiment with different ratios of query types.\n",
    "\n",
    "**Requirements:**\n",
    "1. Create a custom query distribution with different weights than the default\n",
    "2. Generate a new test set using your custom distribution\n",
    "3. Compare the types of questions generated with the default distribution\n",
    "4. Explain why you chose the weights you did"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Custom Distribution:\n",
      "  - Single-hop (simple): 20% (was 50%)\n",
      "  - Multi-hop abstract: 40% (was 25%)\n",
      "  - Multi-hop specific: 40% (was 25%)\n",
      "\n",
      "Generating test set with custom distribution...\n",
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7be00857779844648ecd6e856f964312",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating personas:   0%|          | 0/3 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "88b139dcd5a447a79def39b5d41539fa",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating Scenarios:   0%|          | 0/3 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "18a26d25f72547fa8c36d134f5986746",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating Samples:   0%|          | 0/10 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "================================================================================\n",
      "CUSTOM TEST SET RESULTS\n",
      "================================================================================\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>user_input</th>\n",
       "      <th>reference_contexts</th>\n",
       "      <th>reference</th>\n",
       "      <th>synthesizer_name</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Whaat is the significance of Chicago in the co...</td>\n",
       "      <td>[and my career has essentially been a three-de...</td>\n",
       "      <td>My career has essentially been a three-decade ...</td>\n",
       "      <td>single_hop_specifc_query_synthesizer</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>How do the Florida Keys relate to the Bayesian...</td>\n",
       "      <td>[TODAY‚ÄôS THE DAY Fancy math aside, the foundat...</td>\n",
       "      <td>The Florida Keys are referenced as the area Fi...</td>\n",
       "      <td>single_hop_specifc_query_synthesizer</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>How do hedge fund strategies, such as hedge fu...</td>\n",
       "      <td>[&lt;1-hop&gt;\\n\\nThe Alternative Investments Handbo...</td>\n",
       "      <td>Hedge fund strategies, including hedge fund st...</td>\n",
       "      <td>multi_hop_abstract_query_synthesizer</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>How reinsurance as an investment like ILS and ...</td>\n",
       "      <td>[&lt;1-hop&gt;\\n\\nPART 5: INSURANCE-LINKED INVESTMEN...</td>\n",
       "      <td>Reinsurance as an investment, including Insura...</td>\n",
       "      <td>multi_hop_abstract_query_synthesizer</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>how private equity concepts like J-curve effec...</td>\n",
       "      <td>[&lt;1-hop&gt;\\n\\nThe Alternative Investments Handbo...</td>\n",
       "      <td>The context explains that alternative investme...</td>\n",
       "      <td>multi_hop_abstract_query_synthesizer</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Wht real estate as an asset class can help div...</td>\n",
       "      <td>[&lt;1-hop&gt;\\n\\nThe Alternative Investments Handbo...</td>\n",
       "      <td>Real estate as an asset class provides potenti...</td>\n",
       "      <td>multi_hop_abstract_query_synthesizer</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>How do hedge fund strategies, particularly hed...</td>\n",
       "      <td>[&lt;1-hop&gt;\\n\\nThe Alternative Investments Handbo...</td>\n",
       "      <td>Hedge fund strategies such as long/short equit...</td>\n",
       "      <td>multi_hop_specific_query_synthesizer</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>How does PART 2's detailed explantion of real ...</td>\n",
       "      <td>[&lt;1-hop&gt;\\n\\nPART 2: REAL ESTATE INVESTMENTS Ch...</td>\n",
       "      <td>PART 2 provides an in-depth overview of real e...</td>\n",
       "      <td>multi_hop_specific_query_synthesizer</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>How does the recent performance of Stone Ridge...</td>\n",
       "      <td>[&lt;1-hop&gt;\\n\\nStandardized returns as of most re...</td>\n",
       "      <td>The recent performance of Stone Ridge Energy, ...</td>\n",
       "      <td>multi_hop_specific_query_synthesizer</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>How Chapter 2 and Chapter 4 relate to real est...</td>\n",
       "      <td>[&lt;1-hop&gt;\\n\\nPART 2: REAL ESTATE INVESTMENTS Ch...</td>\n",
       "      <td>Chapter 4 discusses real estate as an asset cl...</td>\n",
       "      <td>multi_hop_specific_query_synthesizer</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                          user_input  \\\n",
       "0  Whaat is the significance of Chicago in the co...   \n",
       "1  How do the Florida Keys relate to the Bayesian...   \n",
       "2  How do hedge fund strategies, such as hedge fu...   \n",
       "3  How reinsurance as an investment like ILS and ...   \n",
       "4  how private equity concepts like J-curve effec...   \n",
       "5  Wht real estate as an asset class can help div...   \n",
       "6  How do hedge fund strategies, particularly hed...   \n",
       "7  How does PART 2's detailed explantion of real ...   \n",
       "8  How does the recent performance of Stone Ridge...   \n",
       "9  How Chapter 2 and Chapter 4 relate to real est...   \n",
       "\n",
       "                                  reference_contexts  \\\n",
       "0  [and my career has essentially been a three-de...   \n",
       "1  [TODAY‚ÄôS THE DAY Fancy math aside, the foundat...   \n",
       "2  [<1-hop>\\n\\nThe Alternative Investments Handbo...   \n",
       "3  [<1-hop>\\n\\nPART 5: INSURANCE-LINKED INVESTMEN...   \n",
       "4  [<1-hop>\\n\\nThe Alternative Investments Handbo...   \n",
       "5  [<1-hop>\\n\\nThe Alternative Investments Handbo...   \n",
       "6  [<1-hop>\\n\\nThe Alternative Investments Handbo...   \n",
       "7  [<1-hop>\\n\\nPART 2: REAL ESTATE INVESTMENTS Ch...   \n",
       "8  [<1-hop>\\n\\nStandardized returns as of most re...   \n",
       "9  [<1-hop>\\n\\nPART 2: REAL ESTATE INVESTMENTS Ch...   \n",
       "\n",
       "                                           reference  \\\n",
       "0  My career has essentially been a three-decade ...   \n",
       "1  The Florida Keys are referenced as the area Fi...   \n",
       "2  Hedge fund strategies, including hedge fund st...   \n",
       "3  Reinsurance as an investment, including Insura...   \n",
       "4  The context explains that alternative investme...   \n",
       "5  Real estate as an asset class provides potenti...   \n",
       "6  Hedge fund strategies such as long/short equit...   \n",
       "7  PART 2 provides an in-depth overview of real e...   \n",
       "8  The recent performance of Stone Ridge Energy, ...   \n",
       "9  Chapter 4 discusses real estate as an asset cl...   \n",
       "\n",
       "                       synthesizer_name  \n",
       "0  single_hop_specifc_query_synthesizer  \n",
       "1  single_hop_specifc_query_synthesizer  \n",
       "2  multi_hop_abstract_query_synthesizer  \n",
       "3  multi_hop_abstract_query_synthesizer  \n",
       "4  multi_hop_abstract_query_synthesizer  \n",
       "5  multi_hop_abstract_query_synthesizer  \n",
       "6  multi_hop_specific_query_synthesizer  \n",
       "7  multi_hop_specific_query_synthesizer  \n",
       "8  multi_hop_specific_query_synthesizer  \n",
       "9  multi_hop_specific_query_synthesizer  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "================================================================================\n",
      "DISTRIBUTION COMPARISON\n",
      "================================================================================\n",
      "\n",
      "Original Distribution (from Cell 18):\n",
      "  single_hop_specifc_query_synthesizer: 5 questions (45.5%)\n",
      "  multi_hop_abstract_query_synthesizer: 3 questions (27.3%)\n",
      "  multi_hop_specific_query_synthesizer: 3 questions (27.3%)\n",
      "\n",
      "Custom Distribution (Activity #1):\n",
      "  multi_hop_abstract_query_synthesizer: 4 questions (40.0%)\n",
      "  multi_hop_specific_query_synthesizer: 4 questions (40.0%)\n",
      "  single_hop_specifc_query_synthesizer: 2 questions (20.0%)\n",
      "\n",
      "================================================================================\n",
      "SAMPLE QUESTIONS COMPARISON\n",
      "================================================================================\n",
      "\n",
      "üìå SINGLE-HOP QUESTIONS (Simple, one chunk):\n",
      "Custom example: Whaat is the significance of Chicago in the context of your career and how does it relate to your current work in Bayesian treasure hunting?\n",
      "\n",
      "üìå MULTI-HOP ABSTRACT QUESTIONS (Conceptual synthesis):\n",
      "Custom example: How do hedge fund strategies, such as hedge fund strategies and managed futures, contribute to diversification and risk management in a portfolio, especially considering their unique return streams and performance metrics like alpha and Sharpe ratio, as discussed in the context of alternative investments and their role in portfolio construction?\n",
      "Another example: How reinsurance as an investment like ILS and cat bonds helps diversify portfolio risk and what are the main risks involved?\n",
      "\n",
      "üìå MULTI-HOP SPECIFIC QUESTIONS (Detailed cross-referencing):\n",
      "Custom example: How do hedge fund strategies, particularly hedge fund strategies like long/short equity and global macro, utilize diversification and risk management techniques discussed in the context of alternative investments to enhance portfolio performance, especially considering their unique fee structures and liquidity terms?\n",
      "Another example: How does PART 2's detailed explantion of real estate asset classes and valuation metrics relate to PART 6's discussion of commodity investing and the role of real assets in diversifying an investment portfolio, especially considering the importance of inflation hedges and low correlation with other assets?\n"
     ]
    }
   ],
   "source": [
    "### YOUR CODE HERE ###\n",
    "\n",
    "# Define a custom query distribution with different weights\n",
    "# focused more on complex queries\n",
    "custom_query_distribution = [\n",
    "    (SingleHopSpecificQuerySynthesizer(llm=generator_llm), 0.2),      # 20% - reduced from 50%\n",
    "    (MultiHopAbstractQuerySynthesizer(llm=generator_llm), 0.4),       # 40% - increased from 25%\n",
    "    (MultiHopSpecificQuerySynthesizer(llm=generator_llm), 0.4),       # 40% - increased from 25%\n",
    "]\n",
    "# Generate a new test set and compare with the default\n",
    "print(\"Custom Distribution:\")\n",
    "print(\"  - Single-hop (simple): 20% (was 50%)\")\n",
    "print(\"  - Multi-hop abstract: 40% (was 25%)\")\n",
    "print(\"  - Multi-hop specific: 40% (was 25%)\")\n",
    "print(\"\\nGenerating test set with custom distribution...\\n\")\n",
    "\n",
    "# Generate new test set with custom distribution\n",
    "custom_generator = TestsetGenerator(\n",
    "    llm=generator_llm,\n",
    "    embedding_model=generator_embeddings,\n",
    "    knowledge_graph=kg  # Reuse the same knowledge graph!\n",
    ")\n",
    "\n",
    "custom_testset = custom_generator.generate(\n",
    "    testset_size=10,\n",
    "    query_distribution=custom_query_distribution\n",
    ")\n",
    "\n",
    "# Display the results\n",
    "custom_df = custom_testset.to_pandas()\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"CUSTOM TEST SET RESULTS\")\n",
    "print(\"=\"*80)\n",
    "display(custom_df)\n",
    "\n",
    "# Compare distributions\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"DISTRIBUTION COMPARISON\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "original_df = testset.to_pandas()\n",
    "\n",
    "print(\"\\nOriginal Distribution (from Cell 18):\")\n",
    "original_counts = original_df['synthesizer_name'].value_counts()\n",
    "for synth, count in original_counts.items():\n",
    "    print(f\"  {synth}: {count} questions ({count/len(original_df)*100:.1f}%)\")\n",
    "\n",
    "print(\"\\nCustom Distribution (Activity #1):\")\n",
    "custom_counts = custom_df['synthesizer_name'].value_counts()\n",
    "for synth, count in custom_counts.items():\n",
    "    print(f\"  {synth}: {count} questions ({count/len(custom_df)*100:.1f}%)\")\n",
    "\n",
    "# Show example questions from each type\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"SAMPLE QUESTIONS COMPARISON\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "print(\"\\nüìå SINGLE-HOP QUESTIONS (Simple, one chunk):\")\n",
    "single_hop_custom = custom_df[custom_df['synthesizer_name'].str.contains('single_hop')]\n",
    "if len(single_hop_custom) > 0:\n",
    "    print(f\"Custom example: {single_hop_custom.iloc[0]['user_input']}\")\n",
    "else:\n",
    "    print(\"(No single-hop questions generated)\")\n",
    "\n",
    "print(\"\\nüìå MULTI-HOP ABSTRACT QUESTIONS (Conceptual synthesis):\")\n",
    "multi_abstract_custom = custom_df[custom_df['synthesizer_name'].str.contains('abstract')]\n",
    "if len(multi_abstract_custom) > 0:\n",
    "    print(f\"Custom example: {multi_abstract_custom.iloc[0]['user_input']}\")\n",
    "    if len(multi_abstract_custom) > 1:\n",
    "        print(f\"Another example: {multi_abstract_custom.iloc[1]['user_input']}\")\n",
    "\n",
    "print(\"\\nüìå MULTI-HOP SPECIFIC QUESTIONS (Detailed cross-referencing):\")\n",
    "multi_specific_custom = custom_df[custom_df['synthesizer_name'].str.contains('specific')]\n",
    "if len(multi_specific_custom) > 0:\n",
    "    print(f\"Custom example: {multi_specific_custom.iloc[0]['user_input']}\")\n",
    "    if len(multi_specific_custom) > 1:\n",
    "        print(f\"Another example: {multi_specific_custom.iloc[1]['user_input']}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "# Part 2: RAG Evaluation with Ragas\n",
    "\n",
    "Now that we have our synthetic test data, we can use it to **systematically evaluate** a RAG pipeline. The idea is simple:\n",
    "1. Build a RAG application\n",
    "2. Run our synthetic queries through it\n",
    "3. Score the results using Ragas metrics\n",
    "4. Make changes and measure the impact\n",
    "\n",
    "This gives us a **data-driven approach** to improving our RAG system, rather than relying on vibes."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Task 5: Building a Baseline RAG Application\n",
    "\n",
    "We'll build a deliberately simple (and somewhat bad) RAG pipeline as our **baseline**, so we can clearly see the impact of improvements later.\n",
    "\n",
    "Our baseline uses:\n",
    "- Tiny chunks (50 characters) with no overlap\n",
    "- A small embedding model (`text-embedding-3-small`)\n",
    "- Only 3 retrieved documents\n",
    "- A basic prompt\n",
    "\n",
    "> **NOTE:** We use the same data that our synthetic test set was generated from ‚Äî this is required because the test questions are specifically designed for this investment data."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### R ‚Äî Retrieval\n",
    "\n",
    "First, we chunk our documents and build a vector store."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2045"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain_text_splitters import RecursiveCharacterTextSplitter\n",
    "\n",
    "text_splitter = RecursiveCharacterTextSplitter(chunk_size=50, chunk_overlap=0)\n",
    "split_documents = text_splitter.split_documents(docs)\n",
    "len(split_documents)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ‚ùì Question #3:\n",
    "\n",
    "What is the purpose of the `chunk_overlap` parameter in the `RecursiveCharacterTextSplitter`?\n",
    "\n",
    "##### ‚úÖ Answer:\n",
    "the purpose of the chuck_overlap parameter is to help maintain context between chunks, ensuring that important information is no lost if a split occurs in the middle of a sentence by duplicating characters between adjacent chunks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_openai import OpenAIEmbeddings\n",
    "\n",
    "embeddings = OpenAIEmbeddings(model=\"text-embedding-3-small\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_qdrant import QdrantVectorStore\n",
    "from qdrant_client import QdrantClient\n",
    "from qdrant_client.http.models import Distance, VectorParams\n",
    "\n",
    "client = QdrantClient(\":memory:\")\n",
    "\n",
    "client.create_collection(\n",
    "    collection_name=\"baseline_rag\",\n",
    "    vectors_config=VectorParams(size=1536, distance=Distance.COSINE),\n",
    ")\n",
    "\n",
    "vector_store = QdrantVectorStore(\n",
    "    client=client,\n",
    "    collection_name=\"baseline_rag\",\n",
    "    embedding=embeddings,\n",
    ")\n",
    "\n",
    "_ = vector_store.add_documents(documents=split_documents)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "retriever = vector_store.as_retriever(search_kwargs={\"k\": 3})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "def retrieve(state):\n",
    "    retrieved_docs = retriever.invoke(state[\"question\"])\n",
    "    return {\"context\": retrieved_docs}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### A ‚Äî Augmented\n",
    "\n",
    "A simple RAG prompt:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "\n",
    "RAG_PROMPT = \"\"\"\\\n",
    "You are a helpful investment advisory assistant who answers questions based on provided context. You must only use the provided context, and cannot use your own knowledge.\n",
    "\n",
    "### Question\n",
    "{question}\n",
    "\n",
    "### Context\n",
    "{context}\n",
    "\"\"\"\n",
    "\n",
    "rag_prompt = ChatPromptTemplate.from_template(RAG_PROMPT)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### G ‚Äî Generation\n",
    "\n",
    "We use `gpt-4.1-nano` for generation to avoid using the same model as our judge model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_openai import ChatOpenAI\n",
    "\n",
    "llm = ChatOpenAI(model=\"gpt-4.1-nano\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate(state):\n",
    "    docs_content = \"\\n\\n\".join(doc.page_content for doc in state[\"context\"])\n",
    "    messages = rag_prompt.format_messages(question=state[\"question\"], context=docs_content)\n",
    "    response = llm.invoke(messages)\n",
    "    return {\"response\": response.content}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Building the RAG Graph with LangGraph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langgraph.graph import START, StateGraph\n",
    "from typing_extensions import List, TypedDict\n",
    "from langchain_core.documents import Document\n",
    "\n",
    "class State(TypedDict):\n",
    "    question: str\n",
    "    context: List[Document]\n",
    "    response: str"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "graph_builder = StateGraph(State).add_sequence([retrieve, generate])\n",
    "graph_builder.add_edge(START, \"retrieve\")\n",
    "graph = graph_builder.compile()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's do a quick sanity check:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Stone Ridge\\'s investment philosophy involves a relentless focus on growing, as indicated by their statement, \"At Stone Ridge, we relentlessly focus on growing.\"'"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "response = graph.invoke({\"question\": \"What is Stone Ridge's investment philosophy?\"})\n",
    "response[\"response\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "With tiny 50-character chunks and only 3 retrieved documents, the baseline likely struggles to provide good answers about Stone Ridge's investment philosophy. That's intentional ‚Äî it gives us room to improve!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Task 6: Evaluating with Ragas\n",
    "\n",
    "Now we can evaluate our baseline RAG against the synthetic test data we generated in Part 1.\n",
    "\n",
    "First, we run all the synthetic queries through our RAG pipeline to collect responses and retrieved contexts."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "for test_row in testset:\n",
    "    response = graph.invoke({\"question\": test_row.eval_sample.user_input})\n",
    "    test_row.eval_sample.response = response[\"response\"]\n",
    "    test_row.eval_sample.retrieved_contexts = [context.page_content for context in response[\"context\"]]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Convert to an `EvaluationDataset` for smoother evaluation:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "from ragas import EvaluationDataset\n",
    "\n",
    "evaluation_dataset = EvaluationDataset.from_pandas(testset.to_pandas())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We select a **judge model** ‚Äî a separate, capable model that scores the outputs. Using a different model than the generator avoids self-evaluation bias."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "from ragas.llms import LangchainLLMWrapper\n",
    "\n",
    "evaluator_llm = LangchainLLMWrapper(ChatOpenAI(model=\"gpt-4.1-mini\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Running the Baseline Evaluation\n",
    "\n",
    "We evaluate across six metrics:\n",
    "- **Context Recall** ‚Äî did we retrieve the relevant context?\n",
    "- **Faithfulness** ‚Äî is the answer grounded in the retrieved context?\n",
    "- **Factual Correctness** ‚Äî is the answer factually correct vs. the reference?\n",
    "- **Answer Relevancy** ‚Äî is the answer relevant to the question?\n",
    "- **Context Entity Recall** ‚Äî did we capture the key entities from the reference context?\n",
    "- **Noise Sensitivity** ‚Äî is the answer affected by irrelevant retrieved content?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c4c36c30d455416696ce4ea4d43983ca",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Evaluating:   0%|          | 0/66 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "{'context_recall': 0.2485, 'faithfulness': 0.4274, 'factual_correctness': 0.4891, 'answer_relevancy': 0.6022, 'context_entity_recall': 0.2465, 'noise_sensitivity_relevant': 0.0000}"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from ragas.metrics import (\n",
    "    LLMContextRecall,\n",
    "    Faithfulness,\n",
    "    FactualCorrectness,\n",
    "    ResponseRelevancy,\n",
    "    ContextEntityRecall,\n",
    "    NoiseSensitivity,\n",
    ")\n",
    "from ragas import evaluate, RunConfig\n",
    "\n",
    "custom_run_config = RunConfig(timeout=360)\n",
    "\n",
    "baseline_result = evaluate(\n",
    "    dataset=evaluation_dataset,\n",
    "    metrics=[\n",
    "        LLMContextRecall(),\n",
    "        Faithfulness(),\n",
    "        FactualCorrectness(),\n",
    "        ResponseRelevancy(),\n",
    "        ContextEntityRecall(),\n",
    "        NoiseSensitivity(),\n",
    "    ],\n",
    "    llm=evaluator_llm,\n",
    "    run_config=custom_run_config,\n",
    ")\n",
    "baseline_result"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Task 7: Making Adjustments and Re-Evaluating\n",
    "\n",
    "Now that we have a baseline, let's improve the pipeline and measure the impact. We'll make three changes:\n",
    "\n",
    "1. **Larger chunks** (500 characters with 30 overlap instead of 50 with 0 overlap)\n",
    "2. **More documents retrieved** (k=20 instead of k=3)\n",
    "3. **Reranking with Cohere** ‚Äî retrieves 20 documents, then uses Cohere's reranker to select the top 5\n",
    "\n",
    "Reranking is a technique that uses a cross-encoder model (slower but more accurate than embedding similarity) on a smaller subset of candidates to improve retrieval precision."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Improved chunking: 202 chunks (vs baseline)\n"
     ]
    }
   ],
   "source": [
    "from langchain_openai import OpenAIEmbeddings\n",
    "from langchain_qdrant import QdrantVectorStore\n",
    "from qdrant_client import QdrantClient\n",
    "from qdrant_client.http.models import Distance, VectorParams\n",
    "\n",
    "text_splitter = RecursiveCharacterTextSplitter(chunk_size=500, chunk_overlap=30)\n",
    "split_documents = text_splitter.split_documents(docs)\n",
    "print(f\"Improved chunking: {len(split_documents)} chunks (vs baseline)\")\n",
    "\n",
    "embeddings = OpenAIEmbeddings(model=\"text-embedding-3-small\")\n",
    "\n",
    "client = QdrantClient(\":memory:\")\n",
    "client.create_collection(\n",
    "    collection_name=\"improved_rag\",\n",
    "    vectors_config=VectorParams(size=1536, distance=Distance.COSINE),\n",
    ")\n",
    "\n",
    "vector_store = QdrantVectorStore(\n",
    "    client=client,\n",
    "    collection_name=\"improved_rag\",\n",
    "    embedding=embeddings,\n",
    ")\n",
    "\n",
    "_ = vector_store.add_documents(documents=split_documents)\n",
    "adjusted_retriever = vector_store.as_retriever(search_kwargs={\"k\": 20})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_classic.retrievers.contextual_compression import (\n",
    "    ContextualCompressionRetriever,\n",
    ")\n",
    "from langchain_cohere import CohereRerank\n",
    "\n",
    "def retrieve_adjusted(state):\n",
    "    compressor = CohereRerank(model=\"rerank-v3.5\")\n",
    "    compression_retriever = ContextualCompressionRetriever(\n",
    "        base_compressor=compressor,\n",
    "        base_retriever=adjusted_retriever,\n",
    "        search_kwargs={\"k\": 5},\n",
    "    )\n",
    "    retrieved_docs = compression_retriever.invoke(state[\"question\"])\n",
    "    return {\"context\": retrieved_docs}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import TypedDict, List\n",
    "from langchain_core.documents import Document\n",
    "\n",
    "class AdjustedState(TypedDict):\n",
    "    question: str\n",
    "    context: List[Document]\n",
    "    response: str\n",
    "\n",
    "adjusted_graph_builder = StateGraph(AdjustedState).add_sequence([retrieve_adjusted, generate])\n",
    "adjusted_graph_builder.add_edge(START, \"retrieve_adjusted\")\n",
    "adjusted_graph = adjusted_graph_builder.compile()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's verify the improved pipeline works:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Stone Ridge approaches risk management in their energy investments through a combination of proprietary securitizations and an integrated approach that leverages \"Flywheel physics\" with their financial strategies. They avoid reliance on legacy-only reinsurers, which are considered riskier due to confirmation bias and adverse selection concerns. Instead, they carefully select their energy assets and utilize proprietary securitizations‚Äîwithout engaging bankers or incurring fee leakage‚Äîto manage risk effectively. Their rigorous and precise financial techniques enable them to navigate the highly volatile natural gas price range, ensuring disciplined risk management across their energy portfolio.'"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "response = adjusted_graph.invoke({\"question\": \"How does Stone Ridge approach risk management in their energy investments?\"})\n",
    "response[\"response\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Running the Improved Evaluation\n",
    "\n",
    "Now let's run the same synthetic test set through our improved pipeline and compare."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "import copy\n",
    "\n",
    "rerank_testset = copy.deepcopy(testset)\n",
    "\n",
    "for test_row in rerank_testset:\n",
    "    response = adjusted_graph.invoke({\"question\": test_row.eval_sample.user_input})\n",
    "    test_row.eval_sample.response = response[\"response\"]\n",
    "    test_row.eval_sample.retrieved_contexts = [context.page_content for context in response[\"context\"]]\n",
    "    time.sleep(7)  # To avoid rate limiting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "64d24730753644acb81f39196bd4b064",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Evaluating:   0%|          | 0/66 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "{'context_recall': 0.5727, 'faithfulness': 0.6853, 'factual_correctness': 0.5327, 'answer_relevancy': 0.9284, 'context_entity_recall': 0.3735, 'noise_sensitivity_relevant': 0.2050}"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rerank_evaluation_dataset = EvaluationDataset.from_pandas(rerank_testset.to_pandas())\n",
    "\n",
    "rerank_result = evaluate(\n",
    "    dataset=rerank_evaluation_dataset,\n",
    "    metrics=[\n",
    "        LLMContextRecall(),\n",
    "        Faithfulness(),\n",
    "        FactualCorrectness(),\n",
    "        ResponseRelevancy(),\n",
    "        ContextEntityRecall(),\n",
    "        NoiseSensitivity(),\n",
    "    ],\n",
    "    llm=evaluator_llm,\n",
    "    run_config=custom_run_config,\n",
    ")\n",
    "rerank_result"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ‚ùì Question #4:\n",
    "\n",
    "Which system performed better, on what metrics, and why?\n",
    "\n",
    "##### ‚úÖ Answer:\n",
    "the rerank system improved on all 5 primary metrics because:\n",
    "1. larger chunks provided complete thoughts instead of sentence fragments\n",
    "2. reranking quality\n",
    "3. better \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ‚ùì Question #5:\n",
    "\n",
    "What are the benefits and limitations of using synthetic data generation for RAG evaluation? Consider both the practical advantages and potential pitfalls.\n",
    "\n",
    "##### ‚úÖ Answer:\n",
    "I think the benefits of using synthetic data generations are:\n",
    "1. can generate test data fast\n",
    "2. can generate diverse tests\n",
    "3. unbiased by human expectations\n",
    "\n",
    "cons:\n",
    "1. not real queries\n",
    "2. quality depends highly on source documents\n",
    "3. over optimization risk"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ‚ùì Question #6:\n",
    "\n",
    "If you were building a production investment advisory assistant for Stone Ridge, which Ragas metrics would be most important to optimize for and why? Consider the financial services domain specifically.\n",
    "\n",
    "##### ‚úÖ Answer:\n",
    "\n",
    "I think the most important Regas metrics would be faithfulness because trust and liability matters a lot when it comes to the financial services domain. Investment advice based on hallucinated information could lead to poor financial decisions. With this being said, I would say topic adherence is the most important ragas metric."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### üèóÔ∏è Activity #2: Implement a Different Reranking Strategy\n",
    "\n",
    "Experiment with different reranking parameters or strategies to see how they affect the evaluation metrics.\n",
    "\n",
    "**Requirements:**\n",
    "1. Modify the `retrieve_adjusted` function to use different parameters (e.g., change `k` values, try different `top_n` for reranking)\n",
    "2. Or implement a different retrieval enhancement strategy (e.g., hybrid search, query expansion)\n",
    "3. Run the evaluation and compare results with the baseline and reranking results above\n",
    "4. Document your findings in the markdown cell below"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "================================================================================\n",
      "STRATEGY 1: AGGRESSIVE RERANKING (k=30 ‚Üí rerank to top 3)\n",
      "================================================================================\n",
      "Chunks: 202\n",
      "\n",
      "Testing aggressive reranking...\n",
      "Sample response: Stone Ridge's investment philosophy is centered on relentlessly focusing on growing after-tax cash flow to drive durable equity value in their operati...\n",
      "\n",
      "Running evaluation (this will take ~70 seconds with rate limiting)...\n",
      "Processed 1/11\n",
      "Processed 2/11\n",
      "Processed 3/11\n",
      "Processed 4/11\n",
      "Processed 5/11\n",
      "Processed 6/11\n",
      "Processed 7/11\n",
      "Processed 8/11\n",
      "Processed 9/11\n",
      "Processed 10/11\n",
      "Processed 11/11\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "77ee5c38c9a14bd4976aef4a00d86847",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Evaluating:   0%|          | 0/66 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "================================================================================\n",
      "RESULTS COMPARISON\n",
      "================================================================================\n",
      "\n",
      "Baseline (k=3, no rerank):\n",
      "  context_recall: 0.2485\n",
      "  faithfulness: 0.4274\n",
      "  factual_correctness: 0.4891\n",
      "  answer_relevancy: 0.6022\n",
      "  context_entity_recall: 0.2465\n",
      "  noise_sensitivity: 0.0000\n",
      "\n",
      "Improved Rerank (k=20 ‚Üí top 5):\n",
      "  context_recall: 0.5727\n",
      "  faithfulness: 0.6853\n",
      "  factual_correctness: 0.5327\n",
      "  answer_relevancy: 0.9284\n",
      "  context_entity_recall: 0.3735\n",
      "  noise_sensitivity: 0.2050\n",
      "\n",
      "Aggressive Rerank (k=30 ‚Üí top 3):\n"
     ]
    },
    {
     "ename": "AttributeError",
     "evalue": "'EvaluationResult' object has no attribute 'items'",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mAttributeError\u001b[39m                            Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[40]\u001b[39m\u001b[32m, line 129\u001b[39m\n\u001b[32m    126\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[33m\"\u001b[39m\u001b[33m  noise_sensitivity: 0.2050\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m    128\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[33mAggressive Rerank (k=30 ‚Üí top 3):\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m--> \u001b[39m\u001b[32m129\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m metric, value \u001b[38;5;129;01min\u001b[39;00m \u001b[43maggressive_result\u001b[49m\u001b[43m.\u001b[49m\u001b[43mitems\u001b[49m():\n\u001b[32m    130\u001b[39m     \u001b[38;5;28mprint\u001b[39m(\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33m  \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mmetric\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mvalue\u001b[38;5;132;01m:\u001b[39;00m\u001b[33m.4f\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m\"\u001b[39m)\n",
      "\u001b[31mAttributeError\u001b[39m: 'EvaluationResult' object has no attribute 'items'"
     ]
    }
   ],
   "source": [
    "### YOUR CODE HERE ###\n",
    "\n",
    "# STRATEGY 1: Aggressive Reranking\n",
    "# Retrieve even more candidates (k=30), but rerank down to top 3 (instead of 5)\n",
    "# Hypothesis: Higher precision with best-of-the-best selection\n",
    "\n",
    "from langchain_text_splitters import RecursiveCharacterTextSplitter\n",
    "from langchain_openai import OpenAIEmbeddings\n",
    "from langchain_qdrant import QdrantVectorStore\n",
    "from qdrant_client import QdrantClient\n",
    "from qdrant_client.http.models import Distance, VectorParams\n",
    "from langchain_classic.retrievers.contextual_compression import ContextualCompressionRetriever\n",
    "from langchain_cohere import CohereRerank\n",
    "from langgraph.graph import START, StateGraph\n",
    "from typing import TypedDict, List\n",
    "from langchain_core.documents import Document\n",
    "import time\n",
    "import copy\n",
    "\n",
    "print(\"=\"*80)\n",
    "print(\"STRATEGY 1: AGGRESSIVE RERANKING (k=30 ‚Üí rerank to top 3)\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "# Same chunking as improved version\n",
    "text_splitter = RecursiveCharacterTextSplitter(chunk_size=500, chunk_overlap=30)\n",
    "split_documents = text_splitter.split_documents(docs)\n",
    "print(f\"Chunks: {len(split_documents)}\")\n",
    "\n",
    "embeddings = OpenAIEmbeddings(model=\"text-embedding-3-small\")\n",
    "\n",
    "client = QdrantClient(\":memory:\")\n",
    "client.create_collection(\n",
    "    collection_name=\"aggressive_rerank\",\n",
    "    vectors_config=VectorParams(size=1536, distance=Distance.COSINE),\n",
    ")\n",
    "\n",
    "vector_store = QdrantVectorStore(\n",
    "    client=client,\n",
    "    collection_name=\"aggressive_rerank\",\n",
    "    embedding=embeddings,\n",
    ")\n",
    "\n",
    "_ = vector_store.add_documents(documents=split_documents)\n",
    "aggressive_retriever = vector_store.as_retriever(search_kwargs={\"k\": 30})  # Increased from 20\n",
    "\n",
    "def retrieve_aggressive(state):\n",
    "    compressor = CohereRerank(model=\"rerank-v3.5\")\n",
    "    compression_retriever = ContextualCompressionRetriever(\n",
    "        base_compressor=compressor,\n",
    "        base_retriever=aggressive_retriever,\n",
    "        search_kwargs={\"k\": 3},  # Reduced from 5 to 3 - only best of the best\n",
    "    )\n",
    "    retrieved_docs = compression_retriever.invoke(state[\"question\"])\n",
    "    return {\"context\": retrieved_docs}\n",
    "\n",
    "class AggressiveState(TypedDict):\n",
    "    question: str\n",
    "    context: List[Document]\n",
    "    response: str\n",
    "\n",
    "aggressive_graph_builder = StateGraph(AggressiveState).add_sequence([retrieve_aggressive, generate])\n",
    "aggressive_graph_builder.add_edge(START, \"retrieve_aggressive\")\n",
    "aggressive_graph = aggressive_graph_builder.compile()\n",
    "\n",
    "# Test it\n",
    "print(\"\\nTesting aggressive reranking...\")\n",
    "test_response = aggressive_graph.invoke({\"question\": \"What is Stone Ridge's investment philosophy?\"})\n",
    "print(f\"Sample response: {test_response['response'][:150]}...\")\n",
    "\n",
    "# Run evaluation\n",
    "print(\"\\nRunning evaluation (this will take ~70 seconds with rate limiting)...\")\n",
    "aggressive_testset = copy.deepcopy(testset)\n",
    "\n",
    "for i, test_row in enumerate(aggressive_testset):\n",
    "    response = aggressive_graph.invoke({\"question\": test_row.eval_sample.user_input})\n",
    "    test_row.eval_sample.response = response[\"response\"]\n",
    "    test_row.eval_sample.retrieved_contexts = [context.page_content for context in response[\"context\"]]\n",
    "    time.sleep(7)  # Rate limiting\n",
    "    print(f\"Processed {i+1}/{len(aggressive_testset)}\")\n",
    "\n",
    "from ragas import EvaluationDataset, evaluate, RunConfig\n",
    "from ragas.metrics import (\n",
    "    LLMContextRecall,\n",
    "    Faithfulness,\n",
    "    FactualCorrectness,\n",
    "    ResponseRelevancy,\n",
    "    ContextEntityRecall,\n",
    "    NoiseSensitivity,\n",
    ")\n",
    "\n",
    "aggressive_evaluation_dataset = EvaluationDataset.from_pandas(aggressive_testset.to_pandas())\n",
    "\n",
    "custom_run_config = RunConfig(timeout=360)\n",
    "\n",
    "aggressive_result = evaluate(\n",
    "    dataset=aggressive_evaluation_dataset,\n",
    "    metrics=[\n",
    "        LLMContextRecall(),\n",
    "        Faithfulness(),\n",
    "        FactualCorrectness(),\n",
    "        ResponseRelevancy(),\n",
    "        ContextEntityRecall(),\n",
    "        NoiseSensitivity(),\n",
    "    ],\n",
    "    llm=evaluator_llm,\n",
    "    run_config=custom_run_config,\n",
    ")\n",
    "\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"RESULTS COMPARISON\")\n",
    "print(\"=\"*80)\n",
    "print(\"\\nBaseline (k=3, no rerank):\")\n",
    "print(\"  context_recall: 0.2485\")\n",
    "print(\"  faithfulness: 0.4274\")\n",
    "print(\"  factual_correctness: 0.4891\")\n",
    "print(\"  answer_relevancy: 0.6022\")\n",
    "print(\"  context_entity_recall: 0.2465\")\n",
    "print(\"  noise_sensitivity: 0.0000\")\n",
    "\n",
    "print(\"\\nImproved Rerank (k=20 ‚Üí top 5):\")\n",
    "print(\"  context_recall: 0.5727\")\n",
    "print(\"  faithfulness: 0.6853\")\n",
    "print(\"  factual_correctness: 0.5327\")\n",
    "print(\"  answer_relevancy: 0.9284\")\n",
    "print(\"  context_entity_recall: 0.3735\")\n",
    "print(\"  noise_sensitivity: 0.2050\")\n",
    "\n",
    "print(f\"\\nAggressive Rerank (k=30 ‚Üí top 3):\")\n",
    "for metric, value in aggressive_result.items():\n",
    "    print(f\"  {metric}: {value:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "================================================================================\n",
      "RESULTS COMPARISON\n",
      "================================================================================\n",
      "\n",
      "Baseline (k=3, no rerank):\n",
      "  context_recall: 0.2485\n",
      "  faithfulness: 0.4274\n",
      "  factual_correctness: 0.4891\n",
      "  answer_relevancy: 0.6022\n",
      "  context_entity_recall: 0.2465\n",
      "  noise_sensitivity: 0.0000\n",
      "\n",
      "Improved Rerank (k=20 ‚Üí top 5):\n",
      "  context_recall: 0.5727\n",
      "  faithfulness: 0.6853\n",
      "  factual_correctness: 0.5327\n",
      "  answer_relevancy: 0.9284\n",
      "  context_entity_recall: 0.3735\n",
      "  noise_sensitivity: 0.2050\n",
      "\n",
      "Aggressive Rerank (k=30 ‚Üí top 3):\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'context_recall': 0.6879, 'faithfulness': 0.7151, 'factual_correctness': 0.5309, 'answer_relevancy': 0.9344, 'context_entity_recall': 0.3518, 'noise_sensitivity_relevant': 0.1816}"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"RESULTS COMPARISON\")\n",
    "print(\"=\"*80)\n",
    "print(\"\\nBaseline (k=3, no rerank):\")\n",
    "print(\"  context_recall: 0.2485\")\n",
    "print(\"  faithfulness: 0.4274\")\n",
    "print(\"  factual_correctness: 0.4891\")\n",
    "print(\"  answer_relevancy: 0.6022\")\n",
    "print(\"  context_entity_recall: 0.2465\")\n",
    "print(\"  noise_sensitivity: 0.0000\")\n",
    "\n",
    "print(\"\\nImproved Rerank (k=20 ‚Üí top 5):\")\n",
    "print(\"  context_recall: 0.5727\")\n",
    "print(\"  faithfulness: 0.6853\")\n",
    "print(\"  factual_correctness: 0.5327\")\n",
    "print(\"  answer_relevancy: 0.9284\")\n",
    "print(\"  context_entity_recall: 0.3735\")\n",
    "print(\"  noise_sensitivity: 0.2050\")\n",
    "\n",
    "print(f\"\\nAggressive Rerank (k=30 ‚Üí top 3):\")\n",
    "aggressive_result"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Activity #2 Findings:\n",
    "\n",
    "*Document your findings here: What strategy did you try? How did it compare to the baseline and reranking results?*\n",
    "\n",
    "#### Strategy Tested: Aggressive Reranking (k=30 ‚Üí rerank to top 3)\n",
    "\n",
    "**Configuration:**\n",
    "- **Baseline:** chunk_size=50, k=3, no rerank\n",
    "- **Improved Rerank:** chunk_size=500, overlap=30, k=20 ‚Üí rerank to top 5\n",
    "- **My Strategy (Aggressive Rerank):** chunk_size=500, overlap=30, k=30 ‚Üí rerank to top 3\n",
    "- **Rationale:** Cast an even wider net (k=30) but be more selective in final selection (top 3 instead of 5). Hypothesis: Higher initial recall combined with more aggressive filtering will improve precision and reduce noise while maintaining good context coverage.\n",
    "\n",
    "#### Results Comparison Table\n",
    "\n",
    "| Metric | Baseline | Improved Rerank (k=20‚Üí5) | Aggressive Rerank (k=30‚Üí3) | Winner |\n",
    "|--------|----------|--------------------------|----------------------------|--------|\n",
    "| **Context Recall** | 0.2485 | 0.5727 | **0.6879** | üèÜ Aggressive (+20%) |\n",
    "| **Faithfulness** | 0.4274 | 0.6853 | **0.7151** | üèÜ Aggressive (+4%) |\n",
    "| **Factual Correctness** | 0.4891 | 0.5327 | 0.5309 | Improved (tie) |\n",
    "| **Answer Relevancy** | 0.6022 | 0.9284 | **0.9344** | üèÜ Aggressive (+1%) |\n",
    "| **Context Entity Recall** | 0.2465 | **0.3735** | 0.3518 | üèÜ Improved (-6%) |\n",
    "| **Noise Sensitivity** | 0.0000 | 0.2050 | **0.1816** | üèÜ Aggressive (-11%) |\n",
    "\n",
    "**Overall Winner: Aggressive Rerank Strategy** - Wins 4 out of 6 metrics, ties on 1, loses on 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## Summary\n",
    "\n",
    "In this notebook, we went end-to-end from data generation to evaluation:\n",
    "\n",
    "1. **Built a knowledge graph** from our investment documents (Stone Ridge 2025 Investor Letter and Alternative Investments Handbook) and used it to understand the structure of our data\n",
    "2. **Generated synthetic test data** with diverse query types (single-hop, multi-hop abstract, multi-hop specific)\n",
    "3. **Built a baseline RAG pipeline** with deliberately simple parameters\n",
    "4. **Evaluated with Ragas** across six metrics to establish a baseline\n",
    "5. **Improved the pipeline** with larger chunks and Cohere reranking\n",
    "6. **Re-evaluated** to measure the impact of our changes\n",
    "\n",
    "### Key Takeaways:\n",
    "\n",
    "- **Synthetic data generation** is critical for early iteration ‚Äî it provides high-quality signal without manually creating test data\n",
    "- **Ragas metrics** give you a multi-dimensional view of RAG quality (retrieval vs. generation vs. faithfulness)\n",
    "- **Small changes matter** ‚Äî chunk size, retrieval strategy, and reranking can dramatically affect evaluation scores\n",
    "- **Always use a different model for judging** than for generating to avoid self-evaluation bias"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "07-synthetic-data-and-evaluation",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
